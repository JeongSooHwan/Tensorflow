{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Classifying Diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.294118 ,  0.487437 ,  0.180328 , ..., -0.53117  , -0.0333333,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.145729 ,  0.0819672, ..., -0.766866 , -0.666667 ,\n",
       "         1.       ],\n",
       "       [-0.0588235,  0.839196 ,  0.0491803, ..., -0.492741 , -0.633333 ,\n",
       "         0.       ],\n",
       "       ...,\n",
       "       [-0.411765 ,  0.21608  ,  0.180328 , ..., -0.857387 , -0.7      ,\n",
       "         1.       ],\n",
       "       [-0.882353 ,  0.266332 , -0.0163934, ..., -0.768574 , -0.133333 ,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.0653266,  0.147541 , ..., -0.797609 , -0.933333 ,\n",
       "         1.       ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice Data X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.294118  ,  0.487437  ,  0.180328  , ...,  0.00149028,\n",
       "        -0.53117   , -0.0333333 ],\n",
       "       [-0.882353  , -0.145729  ,  0.0819672 , ..., -0.207153  ,\n",
       "        -0.766866  , -0.666667  ],\n",
       "       [-0.0588235 ,  0.839196  ,  0.0491803 , ..., -0.305514  ,\n",
       "        -0.492741  , -0.633333  ],\n",
       "       ...,\n",
       "       [-0.411765  ,  0.21608   ,  0.180328  , ..., -0.219076  ,\n",
       "        -0.857387  , -0.7       ],\n",
       "       [-0.882353  ,  0.266332  , -0.0163934 , ..., -0.102832  ,\n",
       "        -0.768574  , -0.133333  ],\n",
       "       [-0.882353  , -0.0653266 ,  0.147541  , ..., -0.0938897 ,\n",
       "        -0.797609  , -0.933333  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([8,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 함수에 W*X+b 값을 넣어줌 --> 결과값 : 0 ~ 1 값\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(Y,predicted), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \n",
      "cost: 2.1342833 \n",
      "Accuracy: 0.342556\n",
      "step: 100 \n",
      "cost: 1.4326553 \n",
      "Accuracy: 0.34123847\n",
      "step: 200 \n",
      "cost: 1.0233072 \n",
      "Accuracy: 0.33596838\n",
      "step: 300 \n",
      "cost: 0.8434038 \n",
      "Accuracy: 0.46113306\n",
      "step: 400 \n",
      "cost: 0.76913506 \n",
      "Accuracy: 0.5362319\n",
      "step: 500 \n",
      "cost: 0.73500925 \n",
      "Accuracy: 0.5704875\n",
      "step: 600 \n",
      "cost: 0.71612346 \n",
      "Accuracy: 0.5836627\n",
      "step: 700 \n",
      "cost: 0.7033481 \n",
      "Accuracy: 0.5928854\n",
      "step: 800 \n",
      "cost: 0.69321215 \n",
      "Accuracy: 0.60474306\n",
      "step: 900 \n",
      "cost: 0.68433887 \n",
      "Accuracy: 0.61528325\n",
      "step: 1000 \n",
      "cost: 0.67616284 \n",
      "Accuracy: 0.62582344\n",
      "step: 1100 \n",
      "cost: 0.6684441 \n",
      "Accuracy: 0.63109356\n",
      "step: 1200 \n",
      "cost: 0.66107756 \n",
      "Accuracy: 0.63109356\n",
      "step: 1300 \n",
      "cost: 0.6540147 \n",
      "Accuracy: 0.6350461\n",
      "step: 1400 \n",
      "cost: 0.64723086 \n",
      "Accuracy: 0.63241106\n",
      "step: 1500 \n",
      "cost: 0.6407113 \n",
      "Accuracy: 0.6350461\n",
      "step: 1600 \n",
      "cost: 0.6344457 \n",
      "Accuracy: 0.63372856\n",
      "step: 1700 \n",
      "cost: 0.62842554 \n",
      "Accuracy: 0.6403162\n",
      "step: 1800 \n",
      "cost: 0.62264305 \n",
      "Accuracy: 0.6469038\n",
      "step: 1900 \n",
      "cost: 0.6170906 \n",
      "Accuracy: 0.6495389\n",
      "step: 2000 \n",
      "cost: 0.61176074 \n",
      "Accuracy: 0.6482214\n",
      "step: 2100 \n",
      "cost: 0.6066461 \n",
      "Accuracy: 0.6508564\n",
      "step: 2200 \n",
      "cost: 0.60173935 \n",
      "Accuracy: 0.65480894\n",
      "step: 2300 \n",
      "cost: 0.59703296 \n",
      "Accuracy: 0.66007906\n",
      "step: 2400 \n",
      "cost: 0.5925199 \n",
      "Accuracy: 0.6640316\n",
      "step: 2500 \n",
      "cost: 0.5881926 \n",
      "Accuracy: 0.6627141\n",
      "step: 2600 \n",
      "cost: 0.5840442 \n",
      "Accuracy: 0.6679842\n",
      "step: 2700 \n",
      "cost: 0.5800676 \n",
      "Accuracy: 0.67193675\n",
      "step: 2800 \n",
      "cost: 0.57625586 \n",
      "Accuracy: 0.6758893\n",
      "step: 2900 \n",
      "cost: 0.5726023 \n",
      "Accuracy: 0.685112\n",
      "step: 3000 \n",
      "cost: 0.5691004 \n",
      "Accuracy: 0.69038206\n",
      "step: 3100 \n",
      "cost: 0.5657437 \n",
      "Accuracy: 0.6916996\n",
      "step: 3200 \n",
      "cost: 0.5625258 \n",
      "Accuracy: 0.6956522\n",
      "step: 3300 \n",
      "cost: 0.559441 \n",
      "Accuracy: 0.69960475\n",
      "step: 3400 \n",
      "cost: 0.5564833 \n",
      "Accuracy: 0.7048748\n",
      "step: 3500 \n",
      "cost: 0.5536472 \n",
      "Accuracy: 0.7035573\n",
      "step: 3600 \n",
      "cost: 0.5509273 \n",
      "Accuracy: 0.7048748\n",
      "step: 3700 \n",
      "cost: 0.54831815 \n",
      "Accuracy: 0.7035573\n",
      "step: 3800 \n",
      "cost: 0.54581493 \n",
      "Accuracy: 0.7061924\n",
      "step: 3900 \n",
      "cost: 0.543413 \n",
      "Accuracy: 0.7088274\n",
      "step: 4000 \n",
      "cost: 0.5411075 \n",
      "Accuracy: 0.715415\n",
      "step: 4100 \n",
      "cost: 0.53889424 \n",
      "Accuracy: 0.71805006\n",
      "step: 4200 \n",
      "cost: 0.53676903 \n",
      "Accuracy: 0.72727275\n",
      "step: 4300 \n",
      "cost: 0.53472775 \n",
      "Accuracy: 0.72859025\n",
      "step: 4400 \n",
      "cost: 0.53276676 \n",
      "Accuracy: 0.72990775\n",
      "step: 4500 \n",
      "cost: 0.5308821 \n",
      "Accuracy: 0.7351779\n",
      "step: 4600 \n",
      "cost: 0.5290708 \n",
      "Accuracy: 0.7351779\n",
      "step: 4700 \n",
      "cost: 0.5273292 \n",
      "Accuracy: 0.7351779\n",
      "step: 4800 \n",
      "cost: 0.5256542 \n",
      "Accuracy: 0.73781294\n",
      "step: 4900 \n",
      "cost: 0.52404296 \n",
      "Accuracy: 0.743083\n",
      "step: 5000 \n",
      "cost: 0.52249247 \n",
      "Accuracy: 0.7483531\n",
      "step: 5100 \n",
      "cost: 0.5210002 \n",
      "Accuracy: 0.75625825\n",
      "step: 5200 \n",
      "cost: 0.5195633 \n",
      "Accuracy: 0.75889325\n",
      "step: 5300 \n",
      "cost: 0.5181796 \n",
      "Accuracy: 0.75757575\n",
      "step: 5400 \n",
      "cost: 0.51684666 \n",
      "Accuracy: 0.7602108\n",
      "step: 5500 \n",
      "cost: 0.5155623 \n",
      "Accuracy: 0.7628459\n",
      "step: 5600 \n",
      "cost: 0.51432437 \n",
      "Accuracy: 0.7628459\n",
      "step: 5700 \n",
      "cost: 0.51313084 \n",
      "Accuracy: 0.7628459\n",
      "step: 5800 \n",
      "cost: 0.5119799 \n",
      "Accuracy: 0.7628459\n",
      "step: 5900 \n",
      "cost: 0.5108696 \n",
      "Accuracy: 0.7615283\n",
      "step: 6000 \n",
      "cost: 0.50979835 \n",
      "Accuracy: 0.7615283\n",
      "step: 6100 \n",
      "cost: 0.5087645 \n",
      "Accuracy: 0.7654809\n",
      "step: 6200 \n",
      "cost: 0.50776637 \n",
      "Accuracy: 0.7654809\n",
      "step: 6300 \n",
      "cost: 0.5068026 \n",
      "Accuracy: 0.7641634\n",
      "step: 6400 \n",
      "cost: 0.50587165 \n",
      "Accuracy: 0.7641634\n",
      "step: 6500 \n",
      "cost: 0.50497234 \n",
      "Accuracy: 0.7641634\n",
      "step: 6600 \n",
      "cost: 0.50410324 \n",
      "Accuracy: 0.7628459\n",
      "step: 6700 \n",
      "cost: 0.5032632 \n",
      "Accuracy: 0.7615283\n",
      "step: 6800 \n",
      "cost: 0.5024509 \n",
      "Accuracy: 0.7615283\n",
      "step: 6900 \n",
      "cost: 0.5016654 \n",
      "Accuracy: 0.7615283\n",
      "step: 7000 \n",
      "cost: 0.5009056 \n",
      "Accuracy: 0.7628459\n",
      "step: 7100 \n",
      "cost: 0.50017047 \n",
      "Accuracy: 0.7641634\n",
      "step: 7200 \n",
      "cost: 0.49945906 \n",
      "Accuracy: 0.7628459\n",
      "step: 7300 \n",
      "cost: 0.49877036 \n",
      "Accuracy: 0.7628459\n",
      "step: 7400 \n",
      "cost: 0.49810362 \n",
      "Accuracy: 0.7628459\n",
      "step: 7500 \n",
      "cost: 0.49745792 \n",
      "Accuracy: 0.7641634\n",
      "step: 7600 \n",
      "cost: 0.4968324 \n",
      "Accuracy: 0.7641634\n",
      "step: 7700 \n",
      "cost: 0.49622652 \n",
      "Accuracy: 0.7641634\n",
      "step: 7800 \n",
      "cost: 0.4956393 \n",
      "Accuracy: 0.7641634\n",
      "step: 7900 \n",
      "cost: 0.49507007 \n",
      "Accuracy: 0.7628459\n",
      "step: 8000 \n",
      "cost: 0.49451837 \n",
      "Accuracy: 0.7628459\n",
      "step: 8100 \n",
      "cost: 0.49398333 \n",
      "Accuracy: 0.7641634\n",
      "step: 8200 \n",
      "cost: 0.49346444 \n",
      "Accuracy: 0.7641634\n",
      "step: 8300 \n",
      "cost: 0.49296102 \n",
      "Accuracy: 0.7641634\n",
      "step: 8400 \n",
      "cost: 0.49247268 \n",
      "Accuracy: 0.7641634\n",
      "step: 8500 \n",
      "cost: 0.4919986 \n",
      "Accuracy: 0.7654809\n",
      "step: 8600 \n",
      "cost: 0.49153867 \n",
      "Accuracy: 0.7641634\n",
      "step: 8700 \n",
      "cost: 0.49109197 \n",
      "Accuracy: 0.7641634\n",
      "step: 8800 \n",
      "cost: 0.49065828 \n",
      "Accuracy: 0.7641634\n",
      "step: 8900 \n",
      "cost: 0.49023718 \n",
      "Accuracy: 0.7641634\n",
      "step: 9000 \n",
      "cost: 0.48982805 \n",
      "Accuracy: 0.7641634\n",
      "step: 9100 \n",
      "cost: 0.48943064 \n",
      "Accuracy: 0.7628459\n",
      "step: 9200 \n",
      "cost: 0.48904434 \n",
      "Accuracy: 0.7628459\n",
      "step: 9300 \n",
      "cost: 0.48866898 \n",
      "Accuracy: 0.7628459\n",
      "step: 9400 \n",
      "cost: 0.48830414 \n",
      "Accuracy: 0.7654809\n",
      "step: 9500 \n",
      "cost: 0.48794943 \n",
      "Accuracy: 0.7654809\n",
      "step: 9600 \n",
      "cost: 0.48760444 \n",
      "Accuracy: 0.7641634\n",
      "step: 9700 \n",
      "cost: 0.48726898 \n",
      "Accuracy: 0.7654809\n",
      "step: 9800 \n",
      "cost: 0.48694262 \n",
      "Accuracy: 0.76811594\n",
      "step: 9900 \n",
      "cost: 0.48662516 \n",
      "Accuracy: 0.770751\n",
      "step: 10000 \n",
      "cost: 0.48631617 \n",
      "Accuracy: 0.770751\n",
      "step: 10100 \n",
      "cost: 0.48601556 \n",
      "Accuracy: 0.76943344\n",
      "step: 10200 \n",
      "cost: 0.485723 \n",
      "Accuracy: 0.76943344\n",
      "step: 10300 \n",
      "cost: 0.48543817 \n",
      "Accuracy: 0.76943344\n",
      "step: 10400 \n",
      "cost: 0.48516074 \n",
      "Accuracy: 0.76943344\n",
      "step: 10500 \n",
      "cost: 0.48489067 \n",
      "Accuracy: 0.770751\n",
      "step: 10600 \n",
      "cost: 0.48462757 \n",
      "Accuracy: 0.76943344\n",
      "step: 10700 \n",
      "cost: 0.48437133 \n",
      "Accuracy: 0.770751\n",
      "step: 10800 \n",
      "cost: 0.48412174 \n",
      "Accuracy: 0.770751\n",
      "step: 10900 \n",
      "cost: 0.4838784 \n",
      "Accuracy: 0.770751\n",
      "step: 11000 \n",
      "cost: 0.48364133 \n",
      "Accuracy: 0.770751\n",
      "step: 11100 \n",
      "cost: 0.48341033 \n",
      "Accuracy: 0.770751\n",
      "step: 11200 \n",
      "cost: 0.48318505 \n",
      "Accuracy: 0.76811594\n",
      "step: 11300 \n",
      "cost: 0.48296544 \n",
      "Accuracy: 0.76811594\n",
      "step: 11400 \n",
      "cost: 0.48275137 \n",
      "Accuracy: 0.76811594\n",
      "step: 11500 \n",
      "cost: 0.48254254 \n",
      "Accuracy: 0.76811594\n",
      "step: 11600 \n",
      "cost: 0.48233888 \n",
      "Accuracy: 0.76811594\n",
      "step: 11700 \n",
      "cost: 0.4821402 \n",
      "Accuracy: 0.76811594\n",
      "step: 11800 \n",
      "cost: 0.48194638 \n",
      "Accuracy: 0.76811594\n",
      "step: 11900 \n",
      "cost: 0.48175728 \n",
      "Accuracy: 0.76811594\n",
      "step: 12000 \n",
      "cost: 0.4815727 \n",
      "Accuracy: 0.76811594\n",
      "step: 12100 \n",
      "cost: 0.48139256 \n",
      "Accuracy: 0.76679844\n",
      "step: 12200 \n",
      "cost: 0.48121673 \n",
      "Accuracy: 0.7654809\n",
      "step: 12300 \n",
      "cost: 0.4810451 \n",
      "Accuracy: 0.7654809\n",
      "step: 12400 \n",
      "cost: 0.48087743 \n",
      "Accuracy: 0.7641634\n",
      "step: 12500 \n",
      "cost: 0.4807138 \n",
      "Accuracy: 0.7641634\n",
      "step: 12600 \n",
      "cost: 0.48055407 \n",
      "Accuracy: 0.7641634\n",
      "step: 12700 \n",
      "cost: 0.48039782 \n",
      "Accuracy: 0.7628459\n",
      "step: 12800 \n",
      "cost: 0.48024532 \n",
      "Accuracy: 0.7628459\n",
      "step: 12900 \n",
      "cost: 0.48009634 \n",
      "Accuracy: 0.7628459\n",
      "step: 13000 \n",
      "cost: 0.4799508 \n",
      "Accuracy: 0.7654809\n",
      "step: 13100 \n",
      "cost: 0.4798085 \n",
      "Accuracy: 0.7654809\n",
      "step: 13200 \n",
      "cost: 0.4796695 \n",
      "Accuracy: 0.7654809\n",
      "step: 13300 \n",
      "cost: 0.4795336 \n",
      "Accuracy: 0.7654809\n",
      "step: 13400 \n",
      "cost: 0.47940072 \n",
      "Accuracy: 0.7641634\n",
      "step: 13500 \n",
      "cost: 0.47927088 \n",
      "Accuracy: 0.7641634\n",
      "step: 13600 \n",
      "cost: 0.47914383 \n",
      "Accuracy: 0.7628459\n",
      "step: 13700 \n",
      "cost: 0.47901967 \n",
      "Accuracy: 0.7628459\n",
      "step: 13800 \n",
      "cost: 0.47889823 \n",
      "Accuracy: 0.7628459\n",
      "step: 13900 \n",
      "cost: 0.47877938 \n",
      "Accuracy: 0.7641634\n",
      "step: 14000 \n",
      "cost: 0.47866318 \n",
      "Accuracy: 0.7641634\n",
      "step: 14100 \n",
      "cost: 0.4785495 \n",
      "Accuracy: 0.7654809\n",
      "step: 14200 \n",
      "cost: 0.47843832 \n",
      "Accuracy: 0.7654809\n",
      "step: 14300 \n",
      "cost: 0.4783295 \n",
      "Accuracy: 0.7654809\n",
      "step: 14400 \n",
      "cost: 0.47822288 \n",
      "Accuracy: 0.7654809\n",
      "step: 14500 \n",
      "cost: 0.47811863 \n",
      "Accuracy: 0.7654809\n",
      "step: 14600 \n",
      "cost: 0.47801656 \n",
      "Accuracy: 0.7654809\n",
      "step: 14700 \n",
      "cost: 0.4779167 \n",
      "Accuracy: 0.7654809\n",
      "step: 14800 \n",
      "cost: 0.4778189 \n",
      "Accuracy: 0.7654809\n",
      "step: 14900 \n",
      "cost: 0.47772312 \n",
      "Accuracy: 0.7654809\n",
      "step: 15000 \n",
      "cost: 0.47762927 \n",
      "Accuracy: 0.7654809\n",
      "step: 15100 \n",
      "cost: 0.47753748 \n",
      "Accuracy: 0.76811594\n",
      "step: 15200 \n",
      "cost: 0.4774476 \n",
      "Accuracy: 0.76811594\n",
      "step: 15300 \n",
      "cost: 0.47735938 \n",
      "Accuracy: 0.76811594\n",
      "step: 15400 \n",
      "cost: 0.47727308 \n",
      "Accuracy: 0.76811594\n",
      "step: 15500 \n",
      "cost: 0.4771884 \n",
      "Accuracy: 0.76811594\n",
      "step: 15600 \n",
      "cost: 0.4771056 \n",
      "Accuracy: 0.76811594\n",
      "step: 15700 \n",
      "cost: 0.47702438 \n",
      "Accuracy: 0.76811594\n",
      "step: 15800 \n",
      "cost: 0.47694483 \n",
      "Accuracy: 0.76811594\n",
      "step: 15900 \n",
      "cost: 0.47686678 \n",
      "Accuracy: 0.76811594\n",
      "step: 16000 \n",
      "cost: 0.47679037 \n",
      "Accuracy: 0.76811594\n",
      "step: 16100 \n",
      "cost: 0.47671536 \n",
      "Accuracy: 0.76811594\n",
      "step: 16200 \n",
      "cost: 0.4766418 \n",
      "Accuracy: 0.76811594\n",
      "step: 16300 \n",
      "cost: 0.47656977 \n",
      "Accuracy: 0.76811594\n",
      "step: 16400 \n",
      "cost: 0.47649908 \n",
      "Accuracy: 0.76811594\n",
      "step: 16500 \n",
      "cost: 0.47642982 \n",
      "Accuracy: 0.76811594\n",
      "step: 16600 \n",
      "cost: 0.4763618 \n",
      "Accuracy: 0.76811594\n",
      "step: 16700 \n",
      "cost: 0.47629517 \n",
      "Accuracy: 0.76811594\n",
      "step: 16800 \n",
      "cost: 0.4762297 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76811594\n",
      "step: 16900 \n",
      "cost: 0.47616562 \n",
      "Accuracy: 0.76811594\n",
      "step: 17000 \n",
      "cost: 0.4761026 \n",
      "Accuracy: 0.76943344\n",
      "step: 17100 \n",
      "cost: 0.47604084 \n",
      "Accuracy: 0.76943344\n",
      "step: 17200 \n",
      "cost: 0.47598034 \n",
      "Accuracy: 0.76943344\n",
      "step: 17300 \n",
      "cost: 0.47592083 \n",
      "Accuracy: 0.76943344\n",
      "step: 17400 \n",
      "cost: 0.4758624 \n",
      "Accuracy: 0.76943344\n",
      "step: 17500 \n",
      "cost: 0.4758051 \n",
      "Accuracy: 0.76943344\n",
      "step: 17600 \n",
      "cost: 0.4757488 \n",
      "Accuracy: 0.76943344\n",
      "step: 17700 \n",
      "cost: 0.4756936 \n",
      "Accuracy: 0.76943344\n",
      "step: 17800 \n",
      "cost: 0.47563937 \n",
      "Accuracy: 0.76943344\n",
      "step: 17900 \n",
      "cost: 0.47558618 \n",
      "Accuracy: 0.76943344\n",
      "step: 18000 \n",
      "cost: 0.47553387 \n",
      "Accuracy: 0.76943344\n",
      "step: 18100 \n",
      "cost: 0.47548243 \n",
      "Accuracy: 0.76943344\n",
      "step: 18200 \n",
      "cost: 0.475432 \n",
      "Accuracy: 0.76943344\n",
      "step: 18300 \n",
      "cost: 0.47538254 \n",
      "Accuracy: 0.76943344\n",
      "step: 18400 \n",
      "cost: 0.47533384 \n",
      "Accuracy: 0.76943344\n",
      "step: 18500 \n",
      "cost: 0.47528604 \n",
      "Accuracy: 0.76943344\n",
      "step: 18600 \n",
      "cost: 0.4752391 \n",
      "Accuracy: 0.76943344\n",
      "step: 18700 \n",
      "cost: 0.4751929 \n",
      "Accuracy: 0.76943344\n",
      "step: 18800 \n",
      "cost: 0.47514755 \n",
      "Accuracy: 0.76943344\n",
      "step: 18900 \n",
      "cost: 0.475103 \n",
      "Accuracy: 0.76943344\n",
      "step: 19000 \n",
      "cost: 0.47505915 \n",
      "Accuracy: 0.76943344\n",
      "step: 19100 \n",
      "cost: 0.4750162 \n",
      "Accuracy: 0.76943344\n",
      "step: 19200 \n",
      "cost: 0.47497386 \n",
      "Accuracy: 0.76943344\n",
      "step: 19300 \n",
      "cost: 0.47493225 \n",
      "Accuracy: 0.76943344\n",
      "step: 19400 \n",
      "cost: 0.4748913 \n",
      "Accuracy: 0.76943344\n",
      "step: 19500 \n",
      "cost: 0.47485113 \n",
      "Accuracy: 0.76943344\n",
      "step: 19600 \n",
      "cost: 0.47481158 \n",
      "Accuracy: 0.76811594\n",
      "step: 19700 \n",
      "cost: 0.4747727 \n",
      "Accuracy: 0.76811594\n",
      "step: 19800 \n",
      "cost: 0.47473451 \n",
      "Accuracy: 0.76811594\n",
      "step: 19900 \n",
      "cost: 0.4746969 \n",
      "Accuracy: 0.76811594\n",
      "step: 20000 \n",
      "cost: 0.47465995 \n",
      "Accuracy: 0.76811594\n",
      "step: 20100 \n",
      "cost: 0.4746235 \n",
      "Accuracy: 0.76811594\n",
      "step: 20200 \n",
      "cost: 0.4745878 \n",
      "Accuracy: 0.76811594\n",
      "step: 20300 \n",
      "cost: 0.4745525 \n",
      "Accuracy: 0.76811594\n",
      "step: 20400 \n",
      "cost: 0.47451785 \n",
      "Accuracy: 0.76811594\n",
      "step: 20500 \n",
      "cost: 0.47448376 \n",
      "Accuracy: 0.76811594\n",
      "step: 20600 \n",
      "cost: 0.47445026 \n",
      "Accuracy: 0.76811594\n",
      "step: 20700 \n",
      "cost: 0.4744172 \n",
      "Accuracy: 0.76679844\n",
      "step: 20800 \n",
      "cost: 0.47438478 \n",
      "Accuracy: 0.76679844\n",
      "step: 20900 \n",
      "cost: 0.4743528 \n",
      "Accuracy: 0.76679844\n",
      "step: 21000 \n",
      "cost: 0.47432134 \n",
      "Accuracy: 0.76679844\n",
      "step: 21100 \n",
      "cost: 0.47429034 \n",
      "Accuracy: 0.76679844\n",
      "step: 21200 \n",
      "cost: 0.47425994 \n",
      "Accuracy: 0.76679844\n",
      "step: 21300 \n",
      "cost: 0.4742298 \n",
      "Accuracy: 0.76679844\n",
      "step: 21400 \n",
      "cost: 0.47420025 \n",
      "Accuracy: 0.76679844\n",
      "step: 21500 \n",
      "cost: 0.47417116 \n",
      "Accuracy: 0.76679844\n",
      "step: 21600 \n",
      "cost: 0.4741425 \n",
      "Accuracy: 0.76679844\n",
      "step: 21700 \n",
      "cost: 0.47411433 \n",
      "Accuracy: 0.76679844\n",
      "step: 21800 \n",
      "cost: 0.47408652 \n",
      "Accuracy: 0.76679844\n",
      "step: 21900 \n",
      "cost: 0.4740591 \n",
      "Accuracy: 0.76679844\n",
      "step: 22000 \n",
      "cost: 0.4740322 \n",
      "Accuracy: 0.76679844\n",
      "step: 22100 \n",
      "cost: 0.4740056 \n",
      "Accuracy: 0.76679844\n",
      "step: 22200 \n",
      "cost: 0.47397947 \n",
      "Accuracy: 0.76679844\n",
      "step: 22300 \n",
      "cost: 0.47395366 \n",
      "Accuracy: 0.76679844\n",
      "step: 22400 \n",
      "cost: 0.4739283 \n",
      "Accuracy: 0.76679844\n",
      "step: 22500 \n",
      "cost: 0.47390324 \n",
      "Accuracy: 0.76679844\n",
      "step: 22600 \n",
      "cost: 0.47387865 \n",
      "Accuracy: 0.76679844\n",
      "step: 22700 \n",
      "cost: 0.47385436 \n",
      "Accuracy: 0.76679844\n",
      "step: 22800 \n",
      "cost: 0.4738304 \n",
      "Accuracy: 0.76679844\n",
      "step: 22900 \n",
      "cost: 0.47380683 \n",
      "Accuracy: 0.76679844\n",
      "step: 23000 \n",
      "cost: 0.47378352 \n",
      "Accuracy: 0.76679844\n",
      "step: 23100 \n",
      "cost: 0.47376063 \n",
      "Accuracy: 0.76679844\n",
      "step: 23200 \n",
      "cost: 0.47373798 \n",
      "Accuracy: 0.76679844\n",
      "step: 23300 \n",
      "cost: 0.47371575 \n",
      "Accuracy: 0.76679844\n",
      "step: 23400 \n",
      "cost: 0.47369382 \n",
      "Accuracy: 0.76679844\n",
      "step: 23500 \n",
      "cost: 0.4736721 \n",
      "Accuracy: 0.76679844\n",
      "step: 23600 \n",
      "cost: 0.47365078 \n",
      "Accuracy: 0.76679844\n",
      "step: 23700 \n",
      "cost: 0.4736297 \n",
      "Accuracy: 0.76679844\n",
      "step: 23800 \n",
      "cost: 0.473609 \n",
      "Accuracy: 0.76679844\n",
      "step: 23900 \n",
      "cost: 0.4735885 \n",
      "Accuracy: 0.76679844\n",
      "step: 24000 \n",
      "cost: 0.47356832 \n",
      "Accuracy: 0.76679844\n",
      "step: 24100 \n",
      "cost: 0.47354838 \n",
      "Accuracy: 0.76679844\n",
      "step: 24200 \n",
      "cost: 0.47352874 \n",
      "Accuracy: 0.76679844\n",
      "step: 24300 \n",
      "cost: 0.4735094 \n",
      "Accuracy: 0.76679844\n",
      "step: 24400 \n",
      "cost: 0.47349027 \n",
      "Accuracy: 0.76679844\n",
      "step: 24500 \n",
      "cost: 0.47347146 \n",
      "Accuracy: 0.76679844\n",
      "step: 24600 \n",
      "cost: 0.4734529 \n",
      "Accuracy: 0.76679844\n",
      "step: 24700 \n",
      "cost: 0.4734345 \n",
      "Accuracy: 0.76679844\n",
      "step: 24800 \n",
      "cost: 0.47341645 \n",
      "Accuracy: 0.76679844\n",
      "step: 24900 \n",
      "cost: 0.47339857 \n",
      "Accuracy: 0.76679844\n",
      "step: 25000 \n",
      "cost: 0.47338098 \n",
      "Accuracy: 0.76679844\n",
      "step: 25100 \n",
      "cost: 0.4733635 \n",
      "Accuracy: 0.76679844\n",
      "step: 25200 \n",
      "cost: 0.47334632 \n",
      "Accuracy: 0.76679844\n",
      "step: 25300 \n",
      "cost: 0.4733294 \n",
      "Accuracy: 0.76679844\n",
      "step: 25400 \n",
      "cost: 0.4733127 \n",
      "Accuracy: 0.76679844\n",
      "step: 25500 \n",
      "cost: 0.47329628 \n",
      "Accuracy: 0.76679844\n",
      "step: 25600 \n",
      "cost: 0.47327992 \n",
      "Accuracy: 0.76679844\n",
      "step: 25700 \n",
      "cost: 0.47326395 \n",
      "Accuracy: 0.76679844\n",
      "step: 25800 \n",
      "cost: 0.47324798 \n",
      "Accuracy: 0.76679844\n",
      "step: 25900 \n",
      "cost: 0.47323236 \n",
      "Accuracy: 0.76679844\n",
      "step: 26000 \n",
      "cost: 0.47321683 \n",
      "Accuracy: 0.76679844\n",
      "step: 26100 \n",
      "cost: 0.47320154 \n",
      "Accuracy: 0.76679844\n",
      "step: 26200 \n",
      "cost: 0.47318652 \n",
      "Accuracy: 0.76679844\n",
      "step: 26300 \n",
      "cost: 0.4731716 \n",
      "Accuracy: 0.76811594\n",
      "step: 26400 \n",
      "cost: 0.47315693 \n",
      "Accuracy: 0.76811594\n",
      "step: 26500 \n",
      "cost: 0.47314236 \n",
      "Accuracy: 0.76811594\n",
      "step: 26600 \n",
      "cost: 0.47312805 \n",
      "Accuracy: 0.76811594\n",
      "step: 26700 \n",
      "cost: 0.47311392 \n",
      "Accuracy: 0.76811594\n",
      "step: 26800 \n",
      "cost: 0.47309983 \n",
      "Accuracy: 0.76811594\n",
      "step: 26900 \n",
      "cost: 0.47308606 \n",
      "Accuracy: 0.76811594\n",
      "step: 27000 \n",
      "cost: 0.47307244 \n",
      "Accuracy: 0.76811594\n",
      "step: 27100 \n",
      "cost: 0.47305888 \n",
      "Accuracy: 0.76811594\n",
      "step: 27200 \n",
      "cost: 0.4730456 \n",
      "Accuracy: 0.76811594\n",
      "step: 27300 \n",
      "cost: 0.4730325 \n",
      "Accuracy: 0.76811594\n",
      "step: 27400 \n",
      "cost: 0.4730194 \n",
      "Accuracy: 0.76811594\n",
      "step: 27500 \n",
      "cost: 0.47300658 \n",
      "Accuracy: 0.76811594\n",
      "step: 27600 \n",
      "cost: 0.47299394 \n",
      "Accuracy: 0.76943344\n",
      "step: 27700 \n",
      "cost: 0.47298136 \n",
      "Accuracy: 0.76943344\n",
      "step: 27800 \n",
      "cost: 0.47296903 \n",
      "Accuracy: 0.76943344\n",
      "step: 27900 \n",
      "cost: 0.47295672 \n",
      "Accuracy: 0.76943344\n",
      "step: 28000 \n",
      "cost: 0.4729447 \n",
      "Accuracy: 0.76943344\n",
      "step: 28100 \n",
      "cost: 0.47293273 \n",
      "Accuracy: 0.76943344\n",
      "step: 28200 \n",
      "cost: 0.4729209 \n",
      "Accuracy: 0.76943344\n",
      "step: 28300 \n",
      "cost: 0.47290918 \n",
      "Accuracy: 0.76943344\n",
      "step: 28400 \n",
      "cost: 0.47289765 \n",
      "Accuracy: 0.76943344\n",
      "step: 28500 \n",
      "cost: 0.47288626 \n",
      "Accuracy: 0.76943344\n",
      "step: 28600 \n",
      "cost: 0.47287497 \n",
      "Accuracy: 0.76943344\n",
      "step: 28700 \n",
      "cost: 0.47286385 \n",
      "Accuracy: 0.76943344\n",
      "step: 28800 \n",
      "cost: 0.4728528 \n",
      "Accuracy: 0.76943344\n",
      "step: 28900 \n",
      "cost: 0.47284192 \n",
      "Accuracy: 0.76943344\n",
      "step: 29000 \n",
      "cost: 0.4728312 \n",
      "Accuracy: 0.76943344\n",
      "step: 29100 \n",
      "cost: 0.47282055 \n",
      "Accuracy: 0.76943344\n",
      "step: 29200 \n",
      "cost: 0.4728099 \n",
      "Accuracy: 0.76943344\n",
      "step: 29300 \n",
      "cost: 0.47279954 \n",
      "Accuracy: 0.76943344\n",
      "step: 29400 \n",
      "cost: 0.47278917 \n",
      "Accuracy: 0.76943344\n",
      "step: 29500 \n",
      "cost: 0.47277912 \n",
      "Accuracy: 0.76943344\n",
      "step: 29600 \n",
      "cost: 0.47276902 \n",
      "Accuracy: 0.76943344\n",
      "step: 29700 \n",
      "cost: 0.47275907 \n",
      "Accuracy: 0.76943344\n",
      "step: 29800 \n",
      "cost: 0.47274926 \n",
      "Accuracy: 0.76943344\n",
      "step: 29900 \n",
      "cost: 0.4727395 \n",
      "Accuracy: 0.76943344\n",
      "step: 30000 \n",
      "cost: 0.47272992 \n",
      "Accuracy: 0.76943344\n",
      "step: 30100 \n",
      "cost: 0.47272035 \n",
      "Accuracy: 0.76943344\n",
      "step: 30200 \n",
      "cost: 0.47271097 \n",
      "Accuracy: 0.76943344\n",
      "step: 30300 \n",
      "cost: 0.47270164 \n",
      "Accuracy: 0.76943344\n",
      "step: 30400 \n",
      "cost: 0.4726924 \n",
      "Accuracy: 0.76943344\n",
      "step: 30500 \n",
      "cost: 0.4726833 \n",
      "Accuracy: 0.76943344\n",
      "step: 30600 \n",
      "cost: 0.47267425 \n",
      "Accuracy: 0.76943344\n",
      "step: 30700 \n",
      "cost: 0.47266537 \n",
      "Accuracy: 0.76943344\n",
      "step: 30800 \n",
      "cost: 0.47265652 \n",
      "Accuracy: 0.76943344\n",
      "step: 30900 \n",
      "cost: 0.47264794 \n",
      "Accuracy: 0.76943344\n",
      "step: 31000 \n",
      "cost: 0.47263917 \n",
      "Accuracy: 0.76943344\n",
      "step: 31100 \n",
      "cost: 0.47263068 \n",
      "Accuracy: 0.76943344\n",
      "step: 31200 \n",
      "cost: 0.47262225 \n",
      "Accuracy: 0.76943344\n",
      "step: 31300 \n",
      "cost: 0.47261384 \n",
      "Accuracy: 0.76943344\n",
      "step: 31400 \n",
      "cost: 0.47260562 \n",
      "Accuracy: 0.76943344\n",
      "step: 31500 \n",
      "cost: 0.47259736 \n",
      "Accuracy: 0.76943344\n",
      "step: 31600 \n",
      "cost: 0.4725893 \n",
      "Accuracy: 0.76943344\n",
      "step: 31700 \n",
      "cost: 0.4725813 \n",
      "Accuracy: 0.76943344\n",
      "step: 31800 \n",
      "cost: 0.47257337 \n",
      "Accuracy: 0.76943344\n",
      "step: 31900 \n",
      "cost: 0.4725655 \n",
      "Accuracy: 0.76943344\n",
      "step: 32000 \n",
      "cost: 0.4725577 \n",
      "Accuracy: 0.76943344\n",
      "step: 32100 \n",
      "cost: 0.47254997 \n",
      "Accuracy: 0.76943344\n",
      "step: 32200 \n",
      "cost: 0.47254238 \n",
      "Accuracy: 0.76943344\n",
      "step: 32300 \n",
      "cost: 0.4725349 \n",
      "Accuracy: 0.76943344\n",
      "step: 32400 \n",
      "cost: 0.47252747 \n",
      "Accuracy: 0.76943344\n",
      "step: 32500 \n",
      "cost: 0.47252005 \n",
      "Accuracy: 0.76943344\n",
      "step: 32600 \n",
      "cost: 0.47251266 \n",
      "Accuracy: 0.76943344\n",
      "step: 32700 \n",
      "cost: 0.4725055 \n",
      "Accuracy: 0.76943344\n",
      "step: 32800 \n",
      "cost: 0.47249836 \n",
      "Accuracy: 0.76943344\n",
      "step: 32900 \n",
      "cost: 0.47249132 \n",
      "Accuracy: 0.76943344\n",
      "step: 33000 \n",
      "cost: 0.47248423 \n",
      "Accuracy: 0.76943344\n",
      "step: 33100 \n",
      "cost: 0.47247732 \n",
      "Accuracy: 0.76943344\n",
      "step: 33200 \n",
      "cost: 0.47247046 \n",
      "Accuracy: 0.76943344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 33300 \n",
      "cost: 0.47246358 \n",
      "Accuracy: 0.76943344\n",
      "step: 33400 \n",
      "cost: 0.4724569 \n",
      "Accuracy: 0.76943344\n",
      "step: 33500 \n",
      "cost: 0.47245023 \n",
      "Accuracy: 0.76943344\n",
      "step: 33600 \n",
      "cost: 0.47244367 \n",
      "Accuracy: 0.76943344\n",
      "step: 33700 \n",
      "cost: 0.47243708 \n",
      "Accuracy: 0.76943344\n",
      "step: 33800 \n",
      "cost: 0.47243056 \n",
      "Accuracy: 0.76943344\n",
      "step: 33900 \n",
      "cost: 0.4724242 \n",
      "Accuracy: 0.76943344\n",
      "step: 34000 \n",
      "cost: 0.47241777 \n",
      "Accuracy: 0.76943344\n",
      "step: 34100 \n",
      "cost: 0.47241154 \n",
      "Accuracy: 0.76943344\n",
      "step: 34200 \n",
      "cost: 0.4724053 \n",
      "Accuracy: 0.76943344\n",
      "step: 34300 \n",
      "cost: 0.47239918 \n",
      "Accuracy: 0.76943344\n",
      "step: 34400 \n",
      "cost: 0.4723931 \n",
      "Accuracy: 0.76943344\n",
      "step: 34500 \n",
      "cost: 0.47238702 \n",
      "Accuracy: 0.76943344\n",
      "step: 34600 \n",
      "cost: 0.47238103 \n",
      "Accuracy: 0.76943344\n",
      "step: 34700 \n",
      "cost: 0.47237515 \n",
      "Accuracy: 0.76943344\n",
      "step: 34800 \n",
      "cost: 0.47236925 \n",
      "Accuracy: 0.76943344\n",
      "step: 34900 \n",
      "cost: 0.4723635 \n",
      "Accuracy: 0.76943344\n",
      "step: 35000 \n",
      "cost: 0.47235763 \n",
      "Accuracy: 0.76943344\n",
      "step: 35100 \n",
      "cost: 0.47235188 \n",
      "Accuracy: 0.76943344\n",
      "step: 35200 \n",
      "cost: 0.47234634 \n",
      "Accuracy: 0.76943344\n",
      "step: 35300 \n",
      "cost: 0.4723408 \n",
      "Accuracy: 0.76943344\n",
      "step: 35400 \n",
      "cost: 0.4723352 \n",
      "Accuracy: 0.76943344\n",
      "step: 35500 \n",
      "cost: 0.47232974 \n",
      "Accuracy: 0.76943344\n",
      "step: 35600 \n",
      "cost: 0.47232422 \n",
      "Accuracy: 0.770751\n",
      "step: 35700 \n",
      "cost: 0.47231886 \n",
      "Accuracy: 0.770751\n",
      "step: 35800 \n",
      "cost: 0.4723135 \n",
      "Accuracy: 0.770751\n",
      "step: 35900 \n",
      "cost: 0.47230816 \n",
      "Accuracy: 0.770751\n",
      "step: 36000 \n",
      "cost: 0.47230297 \n",
      "Accuracy: 0.770751\n",
      "step: 36100 \n",
      "cost: 0.4722978 \n",
      "Accuracy: 0.770751\n",
      "step: 36200 \n",
      "cost: 0.47229266 \n",
      "Accuracy: 0.770751\n",
      "step: 36300 \n",
      "cost: 0.4722876 \n",
      "Accuracy: 0.770751\n",
      "step: 36400 \n",
      "cost: 0.47228247 \n",
      "Accuracy: 0.770751\n",
      "step: 36500 \n",
      "cost: 0.47227752 \n",
      "Accuracy: 0.770751\n",
      "step: 36600 \n",
      "cost: 0.47227255 \n",
      "Accuracy: 0.770751\n",
      "step: 36700 \n",
      "cost: 0.4722677 \n",
      "Accuracy: 0.770751\n",
      "step: 36800 \n",
      "cost: 0.47226286 \n",
      "Accuracy: 0.770751\n",
      "step: 36900 \n",
      "cost: 0.472258 \n",
      "Accuracy: 0.770751\n",
      "step: 37000 \n",
      "cost: 0.4722532 \n",
      "Accuracy: 0.770751\n",
      "step: 37100 \n",
      "cost: 0.4722485 \n",
      "Accuracy: 0.770751\n",
      "step: 37200 \n",
      "cost: 0.47224376 \n",
      "Accuracy: 0.770751\n",
      "step: 37300 \n",
      "cost: 0.47223914 \n",
      "Accuracy: 0.770751\n",
      "step: 37400 \n",
      "cost: 0.47223455 \n",
      "Accuracy: 0.770751\n",
      "step: 37500 \n",
      "cost: 0.47222996 \n",
      "Accuracy: 0.770751\n",
      "step: 37600 \n",
      "cost: 0.47222546 \n",
      "Accuracy: 0.770751\n",
      "step: 37700 \n",
      "cost: 0.47222102 \n",
      "Accuracy: 0.770751\n",
      "step: 37800 \n",
      "cost: 0.47221658 \n",
      "Accuracy: 0.770751\n",
      "step: 37900 \n",
      "cost: 0.47221217 \n",
      "Accuracy: 0.770751\n",
      "step: 38000 \n",
      "cost: 0.4722078 \n",
      "Accuracy: 0.770751\n",
      "step: 38100 \n",
      "cost: 0.47220346 \n",
      "Accuracy: 0.770751\n",
      "step: 38200 \n",
      "cost: 0.47219917 \n",
      "Accuracy: 0.770751\n",
      "step: 38300 \n",
      "cost: 0.47219494 \n",
      "Accuracy: 0.770751\n",
      "step: 38400 \n",
      "cost: 0.47219077 \n",
      "Accuracy: 0.770751\n",
      "step: 38500 \n",
      "cost: 0.47218663 \n",
      "Accuracy: 0.770751\n",
      "step: 38600 \n",
      "cost: 0.47218245 \n",
      "Accuracy: 0.770751\n",
      "step: 38700 \n",
      "cost: 0.47217834 \n",
      "Accuracy: 0.770751\n",
      "step: 38800 \n",
      "cost: 0.4721743 \n",
      "Accuracy: 0.770751\n",
      "step: 38900 \n",
      "cost: 0.4721703 \n",
      "Accuracy: 0.770751\n",
      "step: 39000 \n",
      "cost: 0.47216627 \n",
      "Accuracy: 0.770751\n",
      "step: 39100 \n",
      "cost: 0.47216234 \n",
      "Accuracy: 0.770751\n",
      "step: 39200 \n",
      "cost: 0.4721585 \n",
      "Accuracy: 0.770751\n",
      "step: 39300 \n",
      "cost: 0.4721546 \n",
      "Accuracy: 0.770751\n",
      "step: 39400 \n",
      "cost: 0.47215077 \n",
      "Accuracy: 0.770751\n",
      "step: 39500 \n",
      "cost: 0.47214693 \n",
      "Accuracy: 0.770751\n",
      "step: 39600 \n",
      "cost: 0.4721431 \n",
      "Accuracy: 0.770751\n",
      "step: 39700 \n",
      "cost: 0.4721394 \n",
      "Accuracy: 0.770751\n",
      "step: 39800 \n",
      "cost: 0.47213563 \n",
      "Accuracy: 0.770751\n",
      "step: 39900 \n",
      "cost: 0.47213194 \n",
      "Accuracy: 0.770751\n",
      "step: 40000 \n",
      "cost: 0.47212836 \n",
      "Accuracy: 0.770751\n",
      "step: 40100 \n",
      "cost: 0.47212476 \n",
      "Accuracy: 0.770751\n",
      "step: 40200 \n",
      "cost: 0.47212118 \n",
      "Accuracy: 0.770751\n",
      "step: 40300 \n",
      "cost: 0.4721176 \n",
      "Accuracy: 0.770751\n",
      "step: 40400 \n",
      "cost: 0.47211406 \n",
      "Accuracy: 0.770751\n",
      "step: 40500 \n",
      "cost: 0.47211054 \n",
      "Accuracy: 0.770751\n",
      "step: 40600 \n",
      "cost: 0.47210714 \n",
      "Accuracy: 0.770751\n",
      "step: 40700 \n",
      "cost: 0.47210371 \n",
      "Accuracy: 0.770751\n",
      "step: 40800 \n",
      "cost: 0.47210026 \n",
      "Accuracy: 0.770751\n",
      "step: 40900 \n",
      "cost: 0.47209683 \n",
      "Accuracy: 0.770751\n",
      "step: 41000 \n",
      "cost: 0.47209355 \n",
      "Accuracy: 0.770751\n",
      "step: 41100 \n",
      "cost: 0.4720902 \n",
      "Accuracy: 0.770751\n",
      "step: 41200 \n",
      "cost: 0.47208694 \n",
      "Accuracy: 0.770751\n",
      "step: 41300 \n",
      "cost: 0.47208375 \n",
      "Accuracy: 0.770751\n",
      "step: 41400 \n",
      "cost: 0.47208044 \n",
      "Accuracy: 0.770751\n",
      "step: 41500 \n",
      "cost: 0.47207725 \n",
      "Accuracy: 0.770751\n",
      "step: 41600 \n",
      "cost: 0.47207403 \n",
      "Accuracy: 0.76943344\n",
      "step: 41700 \n",
      "cost: 0.47207096 \n",
      "Accuracy: 0.76943344\n",
      "step: 41800 \n",
      "cost: 0.4720678 \n",
      "Accuracy: 0.76943344\n",
      "step: 41900 \n",
      "cost: 0.47206467 \n",
      "Accuracy: 0.76943344\n",
      "step: 42000 \n",
      "cost: 0.47206163 \n",
      "Accuracy: 0.76943344\n",
      "step: 42100 \n",
      "cost: 0.47205853 \n",
      "Accuracy: 0.76943344\n",
      "step: 42200 \n",
      "cost: 0.47205555 \n",
      "Accuracy: 0.76943344\n",
      "step: 42300 \n",
      "cost: 0.4720526 \n",
      "Accuracy: 0.76943344\n",
      "step: 42400 \n",
      "cost: 0.4720496 \n",
      "Accuracy: 0.76943344\n",
      "step: 42500 \n",
      "cost: 0.4720467 \n",
      "Accuracy: 0.76943344\n",
      "step: 42600 \n",
      "cost: 0.47204372 \n",
      "Accuracy: 0.76943344\n",
      "step: 42700 \n",
      "cost: 0.4720408 \n",
      "Accuracy: 0.76943344\n",
      "step: 42800 \n",
      "cost: 0.47203797 \n",
      "Accuracy: 0.76943344\n",
      "step: 42900 \n",
      "cost: 0.4720351 \n",
      "Accuracy: 0.76943344\n",
      "step: 43000 \n",
      "cost: 0.4720323 \n",
      "Accuracy: 0.76943344\n",
      "step: 43100 \n",
      "cost: 0.4720295 \n",
      "Accuracy: 0.76943344\n",
      "step: 43200 \n",
      "cost: 0.47202677 \n",
      "Accuracy: 0.76943344\n",
      "step: 43300 \n",
      "cost: 0.47202393 \n",
      "Accuracy: 0.76943344\n",
      "step: 43400 \n",
      "cost: 0.47202122 \n",
      "Accuracy: 0.76943344\n",
      "step: 43500 \n",
      "cost: 0.4720185 \n",
      "Accuracy: 0.76943344\n",
      "step: 43600 \n",
      "cost: 0.47201583 \n",
      "Accuracy: 0.76943344\n",
      "step: 43700 \n",
      "cost: 0.47201312 \n",
      "Accuracy: 0.76943344\n",
      "step: 43800 \n",
      "cost: 0.47201058 \n",
      "Accuracy: 0.76943344\n",
      "step: 43900 \n",
      "cost: 0.47200787 \n",
      "Accuracy: 0.76943344\n",
      "step: 44000 \n",
      "cost: 0.47200528 \n",
      "Accuracy: 0.76943344\n",
      "step: 44100 \n",
      "cost: 0.47200269 \n",
      "Accuracy: 0.76943344\n",
      "step: 44200 \n",
      "cost: 0.47200015 \n",
      "Accuracy: 0.76943344\n",
      "step: 44300 \n",
      "cost: 0.47199765 \n",
      "Accuracy: 0.76943344\n",
      "step: 44400 \n",
      "cost: 0.47199515 \n",
      "Accuracy: 0.76943344\n",
      "step: 44500 \n",
      "cost: 0.4719926 \n",
      "Accuracy: 0.76943344\n",
      "step: 44600 \n",
      "cost: 0.47199014 \n",
      "Accuracy: 0.76943344\n",
      "step: 44700 \n",
      "cost: 0.47198772 \n",
      "Accuracy: 0.76943344\n",
      "step: 44800 \n",
      "cost: 0.47198525 \n",
      "Accuracy: 0.76943344\n",
      "step: 44900 \n",
      "cost: 0.47198287 \n",
      "Accuracy: 0.76943344\n",
      "step: 45000 \n",
      "cost: 0.47198048 \n",
      "Accuracy: 0.76943344\n",
      "step: 45100 \n",
      "cost: 0.4719781 \n",
      "Accuracy: 0.76943344\n",
      "step: 45200 \n",
      "cost: 0.47197574 \n",
      "Accuracy: 0.76943344\n",
      "step: 45300 \n",
      "cost: 0.47197345 \n",
      "Accuracy: 0.76943344\n",
      "step: 45400 \n",
      "cost: 0.47197106 \n",
      "Accuracy: 0.76943344\n",
      "step: 45500 \n",
      "cost: 0.47196877 \n",
      "Accuracy: 0.76943344\n",
      "step: 45600 \n",
      "cost: 0.47196653 \n",
      "Accuracy: 0.76943344\n",
      "step: 45700 \n",
      "cost: 0.47196424 \n",
      "Accuracy: 0.76811594\n",
      "step: 45800 \n",
      "cost: 0.47196195 \n",
      "Accuracy: 0.76811594\n",
      "step: 45900 \n",
      "cost: 0.47195977 \n",
      "Accuracy: 0.76811594\n",
      "step: 46000 \n",
      "cost: 0.47195756 \n",
      "Accuracy: 0.76811594\n",
      "step: 46100 \n",
      "cost: 0.47195542 \n",
      "Accuracy: 0.76811594\n",
      "step: 46200 \n",
      "cost: 0.4719533 \n",
      "Accuracy: 0.76811594\n",
      "step: 46300 \n",
      "cost: 0.4719511 \n",
      "Accuracy: 0.76811594\n",
      "step: 46400 \n",
      "cost: 0.47194892 \n",
      "Accuracy: 0.76811594\n",
      "step: 46500 \n",
      "cost: 0.47194684 \n",
      "Accuracy: 0.76811594\n",
      "step: 46600 \n",
      "cost: 0.47194475 \n",
      "Accuracy: 0.76811594\n",
      "step: 46700 \n",
      "cost: 0.47194263 \n",
      "Accuracy: 0.76811594\n",
      "step: 46800 \n",
      "cost: 0.47194055 \n",
      "Accuracy: 0.76811594\n",
      "step: 46900 \n",
      "cost: 0.4719385 \n",
      "Accuracy: 0.76811594\n",
      "step: 47000 \n",
      "cost: 0.47193646 \n",
      "Accuracy: 0.76811594\n",
      "step: 47100 \n",
      "cost: 0.47193444 \n",
      "Accuracy: 0.76811594\n",
      "step: 47200 \n",
      "cost: 0.47193247 \n",
      "Accuracy: 0.76811594\n",
      "step: 47300 \n",
      "cost: 0.47193053 \n",
      "Accuracy: 0.76811594\n",
      "step: 47400 \n",
      "cost: 0.47192854 \n",
      "Accuracy: 0.76811594\n",
      "step: 47500 \n",
      "cost: 0.47192648 \n",
      "Accuracy: 0.76811594\n",
      "step: 47600 \n",
      "cost: 0.47192454 \n",
      "Accuracy: 0.76811594\n",
      "step: 47700 \n",
      "cost: 0.47192267 \n",
      "Accuracy: 0.76811594\n",
      "step: 47800 \n",
      "cost: 0.47192082 \n",
      "Accuracy: 0.76811594\n",
      "step: 47900 \n",
      "cost: 0.47191888 \n",
      "Accuracy: 0.76811594\n",
      "step: 48000 \n",
      "cost: 0.47191703 \n",
      "Accuracy: 0.76811594\n",
      "step: 48100 \n",
      "cost: 0.4719152 \n",
      "Accuracy: 0.76811594\n",
      "step: 48200 \n",
      "cost: 0.47191325 \n",
      "Accuracy: 0.76811594\n",
      "step: 48300 \n",
      "cost: 0.47191143 \n",
      "Accuracy: 0.76811594\n",
      "step: 48400 \n",
      "cost: 0.47190964 \n",
      "Accuracy: 0.76811594\n",
      "step: 48500 \n",
      "cost: 0.47190785 \n",
      "Accuracy: 0.76811594\n",
      "step: 48600 \n",
      "cost: 0.47190607 \n",
      "Accuracy: 0.76811594\n",
      "step: 48700 \n",
      "cost: 0.47190428 \n",
      "Accuracy: 0.76811594\n",
      "step: 48800 \n",
      "cost: 0.47190252 \n",
      "Accuracy: 0.76811594\n",
      "step: 48900 \n",
      "cost: 0.47190076 \n",
      "Accuracy: 0.76811594\n",
      "step: 49000 \n",
      "cost: 0.47189897 \n",
      "Accuracy: 0.76811594\n",
      "step: 49100 \n",
      "cost: 0.4718973 \n",
      "Accuracy: 0.76811594\n",
      "step: 49200 \n",
      "cost: 0.47189564 \n",
      "Accuracy: 0.76811594\n",
      "step: 49300 \n",
      "cost: 0.4718939 \n",
      "Accuracy: 0.76811594\n",
      "step: 49400 \n",
      "cost: 0.47189224 \n",
      "Accuracy: 0.76811594\n",
      "step: 49500 \n",
      "cost: 0.47189057 \n",
      "Accuracy: 0.76811594\n",
      "step: 49600 \n",
      "cost: 0.4718889 \n",
      "Accuracy: 0.76811594\n",
      "step: 49700 \n",
      "cost: 0.47188732 \n",
      "Accuracy: 0.76811594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 49800 \n",
      "cost: 0.47188568 \n",
      "Accuracy: 0.76811594\n",
      "step: 49900 \n",
      "cost: 0.471884 \n",
      "Accuracy: 0.76811594\n",
      "step: 50000 \n",
      "cost: 0.4718824 \n",
      "Accuracy: 0.76811594\n",
      "step: 50100 \n",
      "cost: 0.47188085 \n",
      "Accuracy: 0.76811594\n",
      "step: 50200 \n",
      "cost: 0.4718793 \n",
      "Accuracy: 0.76811594\n",
      "step: 50300 \n",
      "cost: 0.47187772 \n",
      "Accuracy: 0.76811594\n",
      "step: 50400 \n",
      "cost: 0.47187617 \n",
      "Accuracy: 0.76811594\n",
      "step: 50500 \n",
      "cost: 0.47187462 \n",
      "Accuracy: 0.76811594\n",
      "step: 50600 \n",
      "cost: 0.47187313 \n",
      "Accuracy: 0.76811594\n",
      "step: 50700 \n",
      "cost: 0.47187155 \n",
      "Accuracy: 0.76811594\n",
      "step: 50800 \n",
      "cost: 0.47187006 \n",
      "Accuracy: 0.76811594\n",
      "step: 50900 \n",
      "cost: 0.47186857 \n",
      "Accuracy: 0.76811594\n",
      "step: 51000 \n",
      "cost: 0.47186714 \n",
      "Accuracy: 0.76811594\n",
      "step: 51100 \n",
      "cost: 0.4718656 \n",
      "Accuracy: 0.76811594\n",
      "step: 51200 \n",
      "cost: 0.4718642 \n",
      "Accuracy: 0.76811594\n",
      "step: 51300 \n",
      "cost: 0.4718627 \n",
      "Accuracy: 0.76811594\n",
      "step: 51400 \n",
      "cost: 0.47186133 \n",
      "Accuracy: 0.76811594\n",
      "step: 51500 \n",
      "cost: 0.47185987 \n",
      "Accuracy: 0.76811594\n",
      "step: 51600 \n",
      "cost: 0.4718585 \n",
      "Accuracy: 0.76811594\n",
      "step: 51700 \n",
      "cost: 0.47185704 \n",
      "Accuracy: 0.76811594\n",
      "step: 51800 \n",
      "cost: 0.47185567 \n",
      "Accuracy: 0.76811594\n",
      "step: 51900 \n",
      "cost: 0.47185424 \n",
      "Accuracy: 0.76811594\n",
      "step: 52000 \n",
      "cost: 0.4718529 \n",
      "Accuracy: 0.76811594\n",
      "step: 52100 \n",
      "cost: 0.47185153 \n",
      "Accuracy: 0.76811594\n",
      "step: 52200 \n",
      "cost: 0.47185022 \n",
      "Accuracy: 0.76811594\n",
      "step: 52300 \n",
      "cost: 0.47184885 \n",
      "Accuracy: 0.76811594\n",
      "step: 52400 \n",
      "cost: 0.4718475 \n",
      "Accuracy: 0.76811594\n",
      "step: 52500 \n",
      "cost: 0.47184613 \n",
      "Accuracy: 0.76811594\n",
      "step: 52600 \n",
      "cost: 0.4718449 \n",
      "Accuracy: 0.76811594\n",
      "step: 52700 \n",
      "cost: 0.47184354 \n",
      "Accuracy: 0.76811594\n",
      "step: 52800 \n",
      "cost: 0.47184226 \n",
      "Accuracy: 0.76811594\n",
      "step: 52900 \n",
      "cost: 0.47184104 \n",
      "Accuracy: 0.76811594\n",
      "step: 53000 \n",
      "cost: 0.4718398 \n",
      "Accuracy: 0.76811594\n",
      "step: 53100 \n",
      "cost: 0.4718385 \n",
      "Accuracy: 0.76811594\n",
      "step: 53200 \n",
      "cost: 0.4718373 \n",
      "Accuracy: 0.76811594\n",
      "step: 53300 \n",
      "cost: 0.47183606 \n",
      "Accuracy: 0.76811594\n",
      "step: 53400 \n",
      "cost: 0.4718348 \n",
      "Accuracy: 0.76811594\n",
      "step: 53500 \n",
      "cost: 0.47183356 \n",
      "Accuracy: 0.76811594\n",
      "step: 53600 \n",
      "cost: 0.47183236 \n",
      "Accuracy: 0.76811594\n",
      "step: 53700 \n",
      "cost: 0.47183114 \n",
      "Accuracy: 0.76811594\n",
      "step: 53800 \n",
      "cost: 0.47182998 \n",
      "Accuracy: 0.76811594\n",
      "step: 53900 \n",
      "cost: 0.47182882 \n",
      "Accuracy: 0.76811594\n",
      "step: 54000 \n",
      "cost: 0.4718276 \n",
      "Accuracy: 0.76811594\n",
      "step: 54100 \n",
      "cost: 0.47182643 \n",
      "Accuracy: 0.76811594\n",
      "step: 54200 \n",
      "cost: 0.47182527 \n",
      "Accuracy: 0.76811594\n",
      "step: 54300 \n",
      "cost: 0.47182414 \n",
      "Accuracy: 0.76811594\n",
      "step: 54400 \n",
      "cost: 0.47182304 \n",
      "Accuracy: 0.76811594\n",
      "step: 54500 \n",
      "cost: 0.4718219 \n",
      "Accuracy: 0.76811594\n",
      "step: 54600 \n",
      "cost: 0.4718208 \n",
      "Accuracy: 0.76811594\n",
      "step: 54700 \n",
      "cost: 0.4718197 \n",
      "Accuracy: 0.76811594\n",
      "step: 54800 \n",
      "cost: 0.47181857 \n",
      "Accuracy: 0.76811594\n",
      "step: 54900 \n",
      "cost: 0.4718175 \n",
      "Accuracy: 0.76811594\n",
      "step: 55000 \n",
      "cost: 0.47181648 \n",
      "Accuracy: 0.76811594\n",
      "step: 55100 \n",
      "cost: 0.47181526 \n",
      "Accuracy: 0.76811594\n",
      "step: 55200 \n",
      "cost: 0.4718142 \n",
      "Accuracy: 0.76811594\n",
      "step: 55300 \n",
      "cost: 0.47181317 \n",
      "Accuracy: 0.76811594\n",
      "step: 55400 \n",
      "cost: 0.47181204 \n",
      "Accuracy: 0.76811594\n",
      "step: 55500 \n",
      "cost: 0.47181106 \n",
      "Accuracy: 0.76811594\n",
      "step: 55600 \n",
      "cost: 0.47180995 \n",
      "Accuracy: 0.76811594\n",
      "step: 55700 \n",
      "cost: 0.47180894 \n",
      "Accuracy: 0.76811594\n",
      "step: 55800 \n",
      "cost: 0.471808 \n",
      "Accuracy: 0.76811594\n",
      "step: 55900 \n",
      "cost: 0.47180697 \n",
      "Accuracy: 0.76811594\n",
      "step: 56000 \n",
      "cost: 0.47180593 \n",
      "Accuracy: 0.76811594\n",
      "step: 56100 \n",
      "cost: 0.47180507 \n",
      "Accuracy: 0.76811594\n",
      "step: 56200 \n",
      "cost: 0.47180402 \n",
      "Accuracy: 0.76811594\n",
      "step: 56300 \n",
      "cost: 0.47180292 \n",
      "Accuracy: 0.76811594\n",
      "step: 56400 \n",
      "cost: 0.47180203 \n",
      "Accuracy: 0.76811594\n",
      "step: 56500 \n",
      "cost: 0.47180098 \n",
      "Accuracy: 0.76811594\n",
      "step: 56600 \n",
      "cost: 0.47180006 \n",
      "Accuracy: 0.76811594\n",
      "step: 56700 \n",
      "cost: 0.4717991 \n",
      "Accuracy: 0.76811594\n",
      "step: 56800 \n",
      "cost: 0.4717981 \n",
      "Accuracy: 0.76811594\n",
      "step: 56900 \n",
      "cost: 0.47179723 \n",
      "Accuracy: 0.76811594\n",
      "step: 57000 \n",
      "cost: 0.4717963 \n",
      "Accuracy: 0.76811594\n",
      "step: 57100 \n",
      "cost: 0.47179532 \n",
      "Accuracy: 0.76811594\n",
      "step: 57200 \n",
      "cost: 0.47179443 \n",
      "Accuracy: 0.76811594\n",
      "step: 57300 \n",
      "cost: 0.47179356 \n",
      "Accuracy: 0.76811594\n",
      "step: 57400 \n",
      "cost: 0.47179264 \n",
      "Accuracy: 0.76811594\n",
      "step: 57500 \n",
      "cost: 0.47179165 \n",
      "Accuracy: 0.76811594\n",
      "step: 57600 \n",
      "cost: 0.47179085 \n",
      "Accuracy: 0.76811594\n",
      "step: 57700 \n",
      "cost: 0.47179002 \n",
      "Accuracy: 0.76811594\n",
      "step: 57800 \n",
      "cost: 0.471789 \n",
      "Accuracy: 0.76811594\n",
      "step: 57900 \n",
      "cost: 0.4717882 \n",
      "Accuracy: 0.76811594\n",
      "step: 58000 \n",
      "cost: 0.47178733 \n",
      "Accuracy: 0.76811594\n",
      "step: 58100 \n",
      "cost: 0.47178653 \n",
      "Accuracy: 0.76811594\n",
      "step: 58200 \n",
      "cost: 0.47178566 \n",
      "Accuracy: 0.76811594\n",
      "step: 58300 \n",
      "cost: 0.4717848 \n",
      "Accuracy: 0.76811594\n",
      "step: 58400 \n",
      "cost: 0.47178394 \n",
      "Accuracy: 0.76811594\n",
      "step: 58500 \n",
      "cost: 0.47178313 \n",
      "Accuracy: 0.76811594\n",
      "step: 58600 \n",
      "cost: 0.4717823 \n",
      "Accuracy: 0.76811594\n",
      "step: 58700 \n",
      "cost: 0.47178146 \n",
      "Accuracy: 0.76811594\n",
      "step: 58800 \n",
      "cost: 0.47178066 \n",
      "Accuracy: 0.76811594\n",
      "step: 58900 \n",
      "cost: 0.47177988 \n",
      "Accuracy: 0.76811594\n",
      "step: 59000 \n",
      "cost: 0.4717791 \n",
      "Accuracy: 0.76811594\n",
      "step: 59100 \n",
      "cost: 0.47177827 \n",
      "Accuracy: 0.76811594\n",
      "step: 59200 \n",
      "cost: 0.47177744 \n",
      "Accuracy: 0.76679844\n",
      "step: 59300 \n",
      "cost: 0.47177666 \n",
      "Accuracy: 0.76679844\n",
      "step: 59400 \n",
      "cost: 0.47177595 \n",
      "Accuracy: 0.76679844\n",
      "step: 59500 \n",
      "cost: 0.47177523 \n",
      "Accuracy: 0.76679844\n",
      "step: 59600 \n",
      "cost: 0.47177443 \n",
      "Accuracy: 0.76679844\n",
      "step: 59700 \n",
      "cost: 0.47177354 \n",
      "Accuracy: 0.76679844\n",
      "step: 59800 \n",
      "cost: 0.47177294 \n",
      "Accuracy: 0.76679844\n",
      "step: 59900 \n",
      "cost: 0.47177207 \n",
      "Accuracy: 0.76679844\n",
      "step: 60000 \n",
      "cost: 0.47177133 \n",
      "Accuracy: 0.76679844\n",
      "step: 60100 \n",
      "cost: 0.47177064 \n",
      "Accuracy: 0.76679844\n",
      "step: 60200 \n",
      "cost: 0.47176984 \n",
      "Accuracy: 0.76679844\n",
      "step: 60300 \n",
      "cost: 0.4717691 \n",
      "Accuracy: 0.76679844\n",
      "step: 60400 \n",
      "cost: 0.47176844 \n",
      "Accuracy: 0.76679844\n",
      "step: 60500 \n",
      "cost: 0.4717677 \n",
      "Accuracy: 0.76679844\n",
      "step: 60600 \n",
      "cost: 0.471767 \n",
      "Accuracy: 0.76679844\n",
      "step: 60700 \n",
      "cost: 0.4717663 \n",
      "Accuracy: 0.76679844\n",
      "step: 60800 \n",
      "cost: 0.47176564 \n",
      "Accuracy: 0.76679844\n",
      "step: 60900 \n",
      "cost: 0.47176492 \n",
      "Accuracy: 0.76679844\n",
      "step: 61000 \n",
      "cost: 0.4717643 \n",
      "Accuracy: 0.76679844\n",
      "step: 61100 \n",
      "cost: 0.4717635 \n",
      "Accuracy: 0.76679844\n",
      "step: 61200 \n",
      "cost: 0.47176287 \n",
      "Accuracy: 0.76679844\n",
      "step: 61300 \n",
      "cost: 0.47176227 \n",
      "Accuracy: 0.76679844\n",
      "step: 61400 \n",
      "cost: 0.47176152 \n",
      "Accuracy: 0.76679844\n",
      "step: 61500 \n",
      "cost: 0.47176078 \n",
      "Accuracy: 0.76679844\n",
      "step: 61600 \n",
      "cost: 0.47176018 \n",
      "Accuracy: 0.76679844\n",
      "step: 61700 \n",
      "cost: 0.4717596 \n",
      "Accuracy: 0.76679844\n",
      "step: 61800 \n",
      "cost: 0.47175893 \n",
      "Accuracy: 0.76679844\n",
      "step: 61900 \n",
      "cost: 0.47175825 \n",
      "Accuracy: 0.76679844\n",
      "step: 62000 \n",
      "cost: 0.47175756 \n",
      "Accuracy: 0.76679844\n",
      "step: 62100 \n",
      "cost: 0.47175694 \n",
      "Accuracy: 0.76679844\n",
      "step: 62200 \n",
      "cost: 0.4717563 \n",
      "Accuracy: 0.76679844\n",
      "step: 62300 \n",
      "cost: 0.47175577 \n",
      "Accuracy: 0.76679844\n",
      "step: 62400 \n",
      "cost: 0.47175512 \n",
      "Accuracy: 0.76679844\n",
      "step: 62500 \n",
      "cost: 0.47175452 \n",
      "Accuracy: 0.76679844\n",
      "step: 62600 \n",
      "cost: 0.47175387 \n",
      "Accuracy: 0.76679844\n",
      "step: 62700 \n",
      "cost: 0.47175336 \n",
      "Accuracy: 0.76679844\n",
      "step: 62800 \n",
      "cost: 0.47175267 \n",
      "Accuracy: 0.76679844\n",
      "step: 62900 \n",
      "cost: 0.471752 \n",
      "Accuracy: 0.76679844\n",
      "step: 63000 \n",
      "cost: 0.47175142 \n",
      "Accuracy: 0.76679844\n",
      "step: 63100 \n",
      "cost: 0.47175086 \n",
      "Accuracy: 0.76679844\n",
      "step: 63200 \n",
      "cost: 0.47175032 \n",
      "Accuracy: 0.76679844\n",
      "step: 63300 \n",
      "cost: 0.47174972 \n",
      "Accuracy: 0.76679844\n",
      "step: 63400 \n",
      "cost: 0.47174913 \n",
      "Accuracy: 0.76679844\n",
      "step: 63500 \n",
      "cost: 0.4717486 \n",
      "Accuracy: 0.76679844\n",
      "step: 63600 \n",
      "cost: 0.47174805 \n",
      "Accuracy: 0.76679844\n",
      "step: 63700 \n",
      "cost: 0.47174743 \n",
      "Accuracy: 0.76811594\n",
      "step: 63800 \n",
      "cost: 0.47174683 \n",
      "Accuracy: 0.76811594\n",
      "step: 63900 \n",
      "cost: 0.47174633 \n",
      "Accuracy: 0.76811594\n",
      "step: 64000 \n",
      "cost: 0.4717458 \n",
      "Accuracy: 0.76811594\n",
      "step: 64100 \n",
      "cost: 0.4717452 \n",
      "Accuracy: 0.76811594\n",
      "step: 64200 \n",
      "cost: 0.47174463 \n",
      "Accuracy: 0.76811594\n",
      "step: 64300 \n",
      "cost: 0.47174418 \n",
      "Accuracy: 0.76811594\n",
      "step: 64400 \n",
      "cost: 0.47174364 \n",
      "Accuracy: 0.76811594\n",
      "step: 64500 \n",
      "cost: 0.4717431 \n",
      "Accuracy: 0.76811594\n",
      "step: 64600 \n",
      "cost: 0.47174257 \n",
      "Accuracy: 0.76811594\n",
      "step: 64700 \n",
      "cost: 0.47174206 \n",
      "Accuracy: 0.76811594\n",
      "step: 64800 \n",
      "cost: 0.47174156 \n",
      "Accuracy: 0.76811594\n",
      "step: 64900 \n",
      "cost: 0.47174105 \n",
      "Accuracy: 0.76811594\n",
      "step: 65000 \n",
      "cost: 0.47174048 \n",
      "Accuracy: 0.76811594\n",
      "step: 65100 \n",
      "cost: 0.47173995 \n",
      "Accuracy: 0.76811594\n",
      "step: 65200 \n",
      "cost: 0.47173947 \n",
      "Accuracy: 0.76811594\n",
      "step: 65300 \n",
      "cost: 0.47173902 \n",
      "Accuracy: 0.76811594\n",
      "step: 65400 \n",
      "cost: 0.47173852 \n",
      "Accuracy: 0.76811594\n",
      "step: 65500 \n",
      "cost: 0.47173798 \n",
      "Accuracy: 0.76811594\n",
      "step: 65600 \n",
      "cost: 0.47173747 \n",
      "Accuracy: 0.76811594\n",
      "step: 65700 \n",
      "cost: 0.471737 \n",
      "Accuracy: 0.76811594\n",
      "step: 65800 \n",
      "cost: 0.47173655 \n",
      "Accuracy: 0.76811594\n",
      "step: 65900 \n",
      "cost: 0.471736 \n",
      "Accuracy: 0.76811594\n",
      "step: 66000 \n",
      "cost: 0.47173557 \n",
      "Accuracy: 0.76811594\n",
      "step: 66100 \n",
      "cost: 0.47173506 \n",
      "Accuracy: 0.76811594\n",
      "step: 66200 \n",
      "cost: 0.47173464 \n",
      "Accuracy: 0.76811594\n",
      "step: 66300 \n",
      "cost: 0.4717342 \n",
      "Accuracy: 0.76811594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 66400 \n",
      "cost: 0.47173366 \n",
      "Accuracy: 0.76811594\n",
      "step: 66500 \n",
      "cost: 0.47173327 \n",
      "Accuracy: 0.76811594\n",
      "step: 66600 \n",
      "cost: 0.4717328 \n",
      "Accuracy: 0.76811594\n",
      "step: 66700 \n",
      "cost: 0.47173235 \n",
      "Accuracy: 0.76811594\n",
      "step: 66800 \n",
      "cost: 0.47173184 \n",
      "Accuracy: 0.76811594\n",
      "step: 66900 \n",
      "cost: 0.4717314 \n",
      "Accuracy: 0.76811594\n",
      "step: 67000 \n",
      "cost: 0.471731 \n",
      "Accuracy: 0.76811594\n",
      "step: 67100 \n",
      "cost: 0.4717305 \n",
      "Accuracy: 0.76811594\n",
      "step: 67200 \n",
      "cost: 0.47173014 \n",
      "Accuracy: 0.76811594\n",
      "step: 67300 \n",
      "cost: 0.4717297 \n",
      "Accuracy: 0.76811594\n",
      "step: 67400 \n",
      "cost: 0.47172925 \n",
      "Accuracy: 0.76811594\n",
      "step: 67500 \n",
      "cost: 0.47172886 \n",
      "Accuracy: 0.76811594\n",
      "step: 67600 \n",
      "cost: 0.4717284 \n",
      "Accuracy: 0.76811594\n",
      "step: 67700 \n",
      "cost: 0.47172803 \n",
      "Accuracy: 0.76811594\n",
      "step: 67800 \n",
      "cost: 0.47172752 \n",
      "Accuracy: 0.76811594\n",
      "step: 67900 \n",
      "cost: 0.47172722 \n",
      "Accuracy: 0.76811594\n",
      "step: 68000 \n",
      "cost: 0.47172678 \n",
      "Accuracy: 0.76811594\n",
      "step: 68100 \n",
      "cost: 0.47172633 \n",
      "Accuracy: 0.76811594\n",
      "step: 68200 \n",
      "cost: 0.471726 \n",
      "Accuracy: 0.76811594\n",
      "step: 68300 \n",
      "cost: 0.47172555 \n",
      "Accuracy: 0.76811594\n",
      "step: 68400 \n",
      "cost: 0.47172517 \n",
      "Accuracy: 0.76811594\n",
      "step: 68500 \n",
      "cost: 0.4717248 \n",
      "Accuracy: 0.76811594\n",
      "step: 68600 \n",
      "cost: 0.4717244 \n",
      "Accuracy: 0.76811594\n",
      "step: 68700 \n",
      "cost: 0.471724 \n",
      "Accuracy: 0.76811594\n",
      "step: 68800 \n",
      "cost: 0.4717236 \n",
      "Accuracy: 0.76811594\n",
      "step: 68900 \n",
      "cost: 0.47172314 \n",
      "Accuracy: 0.76811594\n",
      "step: 69000 \n",
      "cost: 0.47172284 \n",
      "Accuracy: 0.76811594\n",
      "step: 69100 \n",
      "cost: 0.47172245 \n",
      "Accuracy: 0.76811594\n",
      "step: 69200 \n",
      "cost: 0.47172204 \n",
      "Accuracy: 0.76811594\n",
      "step: 69300 \n",
      "cost: 0.4717217 \n",
      "Accuracy: 0.76811594\n",
      "step: 69400 \n",
      "cost: 0.47172135 \n",
      "Accuracy: 0.76811594\n",
      "step: 69500 \n",
      "cost: 0.47172093 \n",
      "Accuracy: 0.76811594\n",
      "step: 69600 \n",
      "cost: 0.4717206 \n",
      "Accuracy: 0.76811594\n",
      "step: 69700 \n",
      "cost: 0.47172022 \n",
      "Accuracy: 0.76811594\n",
      "step: 69800 \n",
      "cost: 0.47171992 \n",
      "Accuracy: 0.76811594\n",
      "step: 69900 \n",
      "cost: 0.47171953 \n",
      "Accuracy: 0.76811594\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(70000):\n",
    "        cost_val,_,acc = sess.run([cost, train, accuracy],\n",
    "                    feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print('step:',step,'\\ncost:',cost_val,'\\nAccuracy:',acc)\n",
    "            \n",
    "#     h,p,a = sess.run([hypothesis, predicted, accuracy],\n",
    "#             feed_dict={X:x_data, Y:y_data})\n",
    "#     print('Accuracy:',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
