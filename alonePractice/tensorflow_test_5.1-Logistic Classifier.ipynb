{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic(regression) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None,2])\n",
    "Y = tf.placeholder(tf.float32, shape = [None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1 - Y) * tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.cast : 조건에 맞으면 1, 틀리면 0으로 변환됨\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 /cost: 0.7689505 \n",
      "prediction:\n",
      " [[0.18280765]\n",
      " [0.20393988]\n",
      " [0.22036476]\n",
      " [0.24684253]\n",
      " [0.27044603]\n",
      " [0.29284102]]\n",
      "step: 200 /cost: 0.37810138 \n",
      "prediction:\n",
      " [[0.25266063]\n",
      " [0.39031726]\n",
      " [0.5252726 ]\n",
      " [0.683546  ]\n",
      " [0.7986959 ]\n",
      " [0.8760739 ]]\n",
      "step: 400 /cost: 0.3520328 \n",
      "prediction:\n",
      " [[0.20650926]\n",
      " [0.33227825]\n",
      " [0.5428619 ]\n",
      " [0.67835236]\n",
      " [0.81279343]\n",
      " [0.9058664 ]]\n",
      "step: 600 /cost: 0.33479774 \n",
      "prediction:\n",
      " [[0.17651527]\n",
      " [0.29513344]\n",
      " [0.5510675 ]\n",
      " [0.676822  ]\n",
      " [0.8240597 ]\n",
      " [0.92303574]]\n",
      "step: 800 /cost: 0.32170284 \n",
      "prediction:\n",
      " [[0.15556435]\n",
      " [0.27013177]\n",
      " [0.5532671 ]\n",
      " [0.67731833]\n",
      " [0.83329886]\n",
      " [0.93382365]]\n",
      "step: 1000 /cost: 0.31079724 \n",
      "prediction:\n",
      " [[0.14006534]\n",
      " [0.25256786]\n",
      " [0.5515007 ]\n",
      " [0.67900753]\n",
      " [0.84108233]\n",
      " [0.94107175]]\n",
      "step: 1200 /cost: 0.30118898 \n",
      "prediction:\n",
      " [[0.12806198]\n",
      " [0.23978662]\n",
      " [0.54706967]\n",
      " [0.6814437 ]\n",
      " [0.84781253]\n",
      " [0.94621396]]\n",
      "step: 1400 /cost: 0.29243746 \n",
      "prediction:\n",
      " [[0.11841316]\n",
      " [0.23020117]\n",
      " [0.5408337 ]\n",
      " [0.6843636 ]\n",
      " [0.8537643 ]\n",
      " [0.9500333 ]]\n",
      "step: 1600 /cost: 0.28431028 \n",
      "prediction:\n",
      " [[0.11041607]\n",
      " [0.22281578]\n",
      " [0.5333784 ]\n",
      " [0.68759924]\n",
      " [0.8591253 ]\n",
      " [0.9529849 ]]\n",
      "step: 1800 /cost: 0.27667627 \n",
      "prediction:\n",
      " [[0.10361794]\n",
      " [0.21697946]\n",
      " [0.5251118 ]\n",
      " [0.6910364 ]\n",
      " [0.8640251 ]\n",
      " [0.9553471 ]]\n",
      "step: 2000 /cost: 0.2694563 \n",
      "prediction:\n",
      " [[0.09771695]\n",
      " [0.21225367]\n",
      " [0.51632535]\n",
      " [0.69459647]\n",
      " [0.86855507]\n",
      " [0.9572982 ]]\n",
      "step: 2200 /cost: 0.2625993 \n",
      "prediction:\n",
      " [[0.09250578]\n",
      " [0.20833506]\n",
      " [0.5072298 ]\n",
      " [0.69822323]\n",
      " [0.8727806 ]\n",
      " [0.95895547]]\n",
      "step: 2400 /cost: 0.25606912 \n",
      "prediction:\n",
      " [[0.08783821]\n",
      " [0.2050092 ]\n",
      " [0.49797773]\n",
      " [0.701875  ]\n",
      " [0.87674934]\n",
      " [0.96039826]]\n",
      "step: 2600 /cost: 0.24983893 \n",
      "prediction:\n",
      " [[0.08360911]\n",
      " [0.20212302]\n",
      " [0.48868203]\n",
      " [0.7055229 ]\n",
      " [0.88049704]\n",
      " [0.9616815 ]]\n",
      "step: 2800 /cost: 0.24388693 \n",
      "prediction:\n",
      " [[0.07974122]\n",
      " [0.19956522]\n",
      " [0.47942513]\n",
      " [0.7091455 ]\n",
      " [0.88405085]\n",
      " [0.9628438 ]]\n",
      "step: 3000 /cost: 0.23819487 \n",
      "prediction:\n",
      " [[0.07617659]\n",
      " [0.19725403]\n",
      " [0.47026637]\n",
      " [0.71272635]\n",
      " [0.88743114]\n",
      " [0.9639124 ]]\n",
      "step: 3200 /cost: 0.23274654 \n",
      "prediction:\n",
      " [[0.07287121]\n",
      " [0.1951297 ]\n",
      " [0.4612497 ]\n",
      " [0.71625537]\n",
      " [0.8906553 ]\n",
      " [0.96490765]]\n",
      "step: 3400 /cost: 0.22752766 \n",
      "prediction:\n",
      " [[0.06979083]\n",
      " [0.1931475 ]\n",
      " [0.45240533]\n",
      " [0.7197241 ]\n",
      " [0.89373595]\n",
      " [0.9658433 ]]\n",
      "step: 3600 /cost: 0.22252508 \n",
      "prediction:\n",
      " [[0.06690845]\n",
      " [0.19127445]\n",
      " [0.44375497]\n",
      " [0.7231276 ]\n",
      " [0.8966847 ]\n",
      " [0.9667302 ]]\n",
      "step: 3800 /cost: 0.2177266 \n",
      "prediction:\n",
      " [[0.06420245]\n",
      " [0.1894859 ]\n",
      " [0.4353127 ]\n",
      " [0.72646254]\n",
      " [0.8995107 ]\n",
      " [0.9675761 ]]\n",
      "step: 4000 /cost: 0.21312112 \n",
      "prediction:\n",
      " [[0.06165512]\n",
      " [0.18776345]\n",
      " [0.42708713]\n",
      " [0.7297268 ]\n",
      " [0.90222186]\n",
      " [0.9683867 ]]\n",
      "step: 4200 /cost: 0.20869802 \n",
      "prediction:\n",
      " [[0.05925173]\n",
      " [0.18609339]\n",
      " [0.41908306]\n",
      " [0.73291975]\n",
      " [0.90482545]\n",
      " [0.9691664 ]]\n",
      "step: 4400 /cost: 0.20444763 \n",
      "prediction:\n",
      " [[0.05697994]\n",
      " [0.1844656 ]\n",
      " [0.4113021 ]\n",
      " [0.7360413 ]\n",
      " [0.9073275 ]\n",
      " [0.96991843]]\n",
      "step: 4600 /cost: 0.20036076 \n",
      "prediction:\n",
      " [[0.0548291 ]\n",
      " [0.1828724 ]\n",
      " [0.40374297]\n",
      " [0.73909163]\n",
      " [0.9097333 ]\n",
      " [0.9706452 ]]\n",
      "step: 4800 /cost: 0.19642876 \n",
      "prediction:\n",
      " [[0.05279004]\n",
      " [0.18130815]\n",
      " [0.39640334]\n",
      " [0.74207187]\n",
      " [0.9120481 ]\n",
      " [0.9713488 ]]\n",
      "step: 5000 /cost: 0.19264358 \n",
      "prediction:\n",
      " [[0.05085471]\n",
      " [0.17976889]\n",
      " [0.38927963]\n",
      " [0.7449836 ]\n",
      " [0.9142767 ]\n",
      " [0.97203076]]\n",
      "step: 5200 /cost: 0.18899776 \n",
      "prediction:\n",
      " [[0.04901599]\n",
      " [0.17825165]\n",
      " [0.3823673 ]\n",
      " [0.7478283 ]\n",
      " [0.9164233 ]\n",
      " [0.9726924 ]]\n",
      "step: 5400 /cost: 0.18548422 \n",
      "prediction:\n",
      " [[0.0472674 ]\n",
      " [0.17675406]\n",
      " [0.3756604 ]\n",
      " [0.75060695]\n",
      " [0.91849154]\n",
      " [0.97333443]]\n",
      "step: 5600 /cost: 0.18209626 \n",
      "prediction:\n",
      " [[0.04560324]\n",
      " [0.17527467]\n",
      " [0.3691536 ]\n",
      " [0.75332177]\n",
      " [0.9204854 ]\n",
      " [0.973958  ]]\n",
      "step: 5800 /cost: 0.17882763 \n",
      "prediction:\n",
      " [[0.04401821]\n",
      " [0.17381258]\n",
      " [0.36284086]\n",
      " [0.7559748 ]\n",
      " [0.9224083 ]\n",
      " [0.97456384]]\n",
      "step: 6000 /cost: 0.17567247 \n",
      "prediction:\n",
      " [[0.04250752]\n",
      " [0.17236663]\n",
      " [0.35671556]\n",
      " [0.7585671 ]\n",
      " [0.9242632 ]\n",
      " [0.97515225]]\n",
      "step: 6200 /cost: 0.17262526 \n",
      "prediction:\n",
      " [[0.04106679]\n",
      " [0.17093688]\n",
      " [0.35077238]\n",
      " [0.7611015 ]\n",
      " [0.92605364]\n",
      " [0.9757243 ]]\n",
      "step: 6400 /cost: 0.16968073 \n",
      "prediction:\n",
      " [[0.03969187]\n",
      " [0.16952232]\n",
      " [0.34500378]\n",
      " [0.76357865]\n",
      " [0.9277821 ]\n",
      " [0.97628003]]\n",
      "step: 6600 /cost: 0.16683418 \n",
      "prediction:\n",
      " [[0.03837913]\n",
      " [0.16812342]\n",
      " [0.33940497]\n",
      " [0.7660012 ]\n",
      " [0.9294516 ]\n",
      " [0.97682035]]\n",
      "step: 6800 /cost: 0.16408089 \n",
      "prediction:\n",
      " [[0.03712498]\n",
      " [0.16673979]\n",
      " [0.33396932]\n",
      " [0.76837075]\n",
      " [0.9310645 ]\n",
      " [0.97734547]]\n",
      "step: 7000 /cost: 0.16141655 \n",
      "prediction:\n",
      " [[0.03592623]\n",
      " [0.16537139]\n",
      " [0.32869104]\n",
      " [0.7706887 ]\n",
      " [0.93262327]\n",
      " [0.977856  ]]\n",
      "step: 7200 /cost: 0.158837 \n",
      "prediction:\n",
      " [[0.03477981]\n",
      " [0.16401814]\n",
      " [0.32356396]\n",
      " [0.77295667]\n",
      " [0.9341303 ]\n",
      " [0.97835207]]\n",
      "step: 7400 /cost: 0.15633853 \n",
      "prediction:\n",
      " [[0.03368293]\n",
      " [0.16268022]\n",
      " [0.31858328]\n",
      " [0.77517647]\n",
      " [0.9355879 ]\n",
      " [0.9788344 ]]\n",
      "step: 7600 /cost: 0.15391749 \n",
      "prediction:\n",
      " [[0.03263295]\n",
      " [0.16135767]\n",
      " [0.3137435 ]\n",
      " [0.7773498 ]\n",
      " [0.93699795]\n",
      " [0.97930324]]\n",
      "step: 7800 /cost: 0.1515703 \n",
      "prediction:\n",
      " [[0.03162734]\n",
      " [0.16005023]\n",
      " [0.30903888]\n",
      " [0.7794777 ]\n",
      " [0.9383624 ]\n",
      " [0.97975916]]\n",
      "step: 8000 /cost: 0.14929388 \n",
      "prediction:\n",
      " [[0.0306638 ]\n",
      " [0.15875797]\n",
      " [0.3044644 ]\n",
      " [0.7815613 ]\n",
      " [0.93968314]\n",
      " [0.98020226]]\n",
      "step: 8200 /cost: 0.14708509 \n",
      "prediction:\n",
      " [[0.02974021]\n",
      " [0.15748122]\n",
      " [0.30001637]\n",
      " [0.7836033 ]\n",
      " [0.9409624 ]\n",
      " [0.9806331 ]]\n",
      "step: 8400 /cost: 0.14494108 \n",
      "prediction:\n",
      " [[0.02885447]\n",
      " [0.1562197 ]\n",
      " [0.2956888 ]\n",
      " [0.78560346]\n",
      " [0.94220126]\n",
      " [0.9810519 ]]\n",
      "step: 8600 /cost: 0.14285906 \n",
      "prediction:\n",
      " [[0.02800468]\n",
      " [0.15497348]\n",
      " [0.2914783 ]\n",
      " [0.7875642 ]\n",
      " [0.9434018 ]\n",
      " [0.98145926]]\n",
      "step: 8800 /cost: 0.14083648 \n",
      "prediction:\n",
      " [[0.02718905]\n",
      " [0.15374245]\n",
      " [0.28738025]\n",
      " [0.78948635]\n",
      " [0.9445653 ]\n",
      " [0.9818553 ]]\n",
      "step: 9000 /cost: 0.13887087 \n",
      "prediction:\n",
      " [[0.02640582]\n",
      " [0.15252653]\n",
      " [0.28339002]\n",
      " [0.7913706 ]\n",
      " [0.9456933 ]\n",
      " [0.9822404 ]]\n",
      "step: 9200 /cost: 0.13695991 \n",
      "prediction:\n",
      " [[0.02565347]\n",
      " [0.15132585]\n",
      " [0.27950487]\n",
      " [0.793219  ]\n",
      " [0.94678736]\n",
      " [0.982615  ]]\n",
      "step: 9400 /cost: 0.1351014 \n",
      "prediction:\n",
      " [[0.02493043]\n",
      " [0.1501402 ]\n",
      " [0.27572   ]\n",
      " [0.7950319 ]\n",
      " [0.9478485 ]\n",
      " [0.98297924]]\n",
      "step: 9600 /cost: 0.13329329 \n",
      "prediction:\n",
      " [[0.02423537]\n",
      " [0.14896975]\n",
      " [0.27203277]\n",
      " [0.7968111 ]\n",
      " [0.9488784 ]\n",
      " [0.98333365]]\n",
      "step: 9800 /cost: 0.13153349 \n",
      "prediction:\n",
      " [[0.02356683]\n",
      " [0.14781387]\n",
      " [0.26843873]\n",
      " [0.7985567 ]\n",
      " [0.949878  ]\n",
      " [0.98367834]]\n",
      "step: 10000 /cost: 0.12982017 \n",
      "prediction:\n",
      " [[0.02292359]\n",
      " [0.14667276]\n",
      " [0.2649351 ]\n",
      " [0.8002702 ]\n",
      " [0.9508484 ]\n",
      " [0.98401374]]\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     for step in range(10001):\n",
    "#         cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "#                             feed_dict={X:x_data, Y:y_data})\n",
    "#         if step % 200 == 0:\n",
    "#             print('step:',step,'/cost:',cost_val,'\\nprediction:\\n', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 /cost: 4.277661 \n",
      "prediction:\n",
      " [[4.4980042e-02]\n",
      " [6.8550687e-03]\n",
      " [7.2863731e-03]\n",
      " [5.5531447e-04]\n",
      " [1.5761681e-04]\n",
      " [8.6581014e-05]]\n",
      "step: 200 /cost: 0.5273773 \n",
      "prediction:\n",
      " [[0.42607105]\n",
      " [0.4808628 ]\n",
      " [0.6296483 ]\n",
      " [0.65098256]\n",
      " [0.7257837 ]\n",
      " [0.81030124]]\n",
      "step: 400 /cost: 0.47255817 \n",
      "prediction:\n",
      " [[0.3332753 ]\n",
      " [0.38400432]\n",
      " [0.656072  ]\n",
      " [0.63817686]\n",
      " [0.7479074 ]\n",
      " [0.8706487 ]]\n",
      "step: 600 /cost: 0.4412789 \n",
      "prediction:\n",
      " [[0.27586854]\n",
      " [0.3269058 ]\n",
      " [0.6681653 ]\n",
      " [0.63405246]\n",
      " [0.76594764]\n",
      " [0.9015519 ]]\n",
      "step: 800 /cost: 0.41958377 \n",
      "prediction:\n",
      " [[0.23770003]\n",
      " [0.2913004 ]\n",
      " [0.6715898 ]\n",
      " [0.633881  ]\n",
      " [0.78038174]\n",
      " [0.9190581 ]]\n",
      "step: 1000 /cost: 0.40239492 \n",
      "prediction:\n",
      " [[0.21060355]\n",
      " [0.2678747 ]\n",
      " [0.6695396 ]\n",
      " [0.63569707]\n",
      " [0.79213136]\n",
      " [0.9298333 ]]\n",
      "step: 1200 /cost: 0.3876358 \n",
      "prediction:\n",
      " [[0.19030604]\n",
      " [0.2517941 ]\n",
      " [0.6639131 ]\n",
      " [0.63863415]\n",
      " [0.8019766 ]\n",
      " [0.936923  ]]\n",
      "step: 1400 /cost: 0.37437057 \n",
      "prediction:\n",
      " [[0.1744179 ]\n",
      " [0.24037349]\n",
      " [0.6558925 ]\n",
      " [0.64225227]\n",
      " [0.8104668 ]\n",
      " [0.94185054]]\n",
      "step: 1600 /cost: 0.36214253 \n",
      "prediction:\n",
      " [[0.16152143]\n",
      " [0.23202449]\n",
      " [0.64625156]\n",
      " [0.64629936]\n",
      " [0.81797314]\n",
      " [0.9454408 ]]\n",
      "step: 1800 /cost: 0.3507116 \n",
      "prediction:\n",
      " [[0.15073359]\n",
      " [0.22575739]\n",
      " [0.6355197 ]\n",
      " [0.6506168 ]\n",
      " [0.8247461 ]\n",
      " [0.9481708 ]]\n",
      "step: 2000 /cost: 0.33994222 \n",
      "prediction:\n",
      " [[0.14148244]\n",
      " [0.22092977]\n",
      " [0.62407273]\n",
      " [0.655099  ]\n",
      " [0.8309565 ]\n",
      " [0.95033115]]\n",
      "step: 2200 /cost: 0.32975066 \n",
      "prediction:\n",
      " [[0.13338506]\n",
      " [0.21711032]\n",
      " [0.6121838 ]\n",
      " [0.65967125]\n",
      " [0.83672196]\n",
      " [0.952106  ]]\n",
      "step: 2400 /cost: 0.32008028 \n",
      "prediction:\n",
      " [[0.12617837]\n",
      " [0.21400252]\n",
      " [0.6000543 ]\n",
      " [0.6642796 ]\n",
      " [0.8421243 ]\n",
      " [0.95361555]]\n",
      "step: 2600 /cost: 0.31088966 \n",
      "prediction:\n",
      " [[0.11967756]\n",
      " [0.21139908]\n",
      " [0.5878354 ]\n",
      " [0.6688846 ]\n",
      " [0.8472215 ]\n",
      " [0.9549401 ]]\n",
      "step: 2800 /cost: 0.30214527 \n",
      "prediction:\n",
      " [[0.11374998]\n",
      " [0.2091529 ]\n",
      " [0.57564   ]\n",
      " [0.67345726]\n",
      " [0.85205555]\n",
      " [0.9561341 ]]\n",
      "step: 3000 /cost: 0.2938186 \n",
      "prediction:\n",
      " [[0.10829857]\n",
      " [0.20715886]\n",
      " [0.56355256]\n",
      " [0.677976  ]\n",
      " [0.85665697]\n",
      " [0.9572345 ]]\n",
      "step: 3200 /cost: 0.28588438 \n",
      "prediction:\n",
      " [[0.10325114]\n",
      " [0.20534162]\n",
      " [0.5516363 ]\n",
      " [0.682426  ]\n",
      " [0.86104935]\n",
      " [0.9582672 ]]\n",
      "step: 3400 /cost: 0.27831957 \n",
      "prediction:\n",
      " [[0.0985527 ]\n",
      " [0.20364688]\n",
      " [0.53993726]\n",
      " [0.68679583]\n",
      " [0.86525035]\n",
      " [0.9592495 ]]\n",
      "step: 3600 /cost: 0.27110285 \n",
      "prediction:\n",
      " [[0.0941608 ]\n",
      " [0.20203568]\n",
      " [0.5284887 ]\n",
      " [0.69107795]\n",
      " [0.8692741 ]\n",
      " [0.96019334]]\n",
      "step: 3800 /cost: 0.2642143 \n",
      "prediction:\n",
      " [[0.09004176]\n",
      " [0.20048009]\n",
      " [0.5173136 ]\n",
      " [0.6952672 ]\n",
      " [0.873132  ]\n",
      " [0.96110684]]\n",
      "step: 4000 /cost: 0.25763524 \n",
      "prediction:\n",
      " [[0.08616869]\n",
      " [0.19896083]\n",
      " [0.5064278 ]\n",
      " [0.6993612 ]\n",
      " [0.8768343 ]\n",
      " [0.96199566]]\n",
      "step: 4200 /cost: 0.2513482 \n",
      "prediction:\n",
      " [[0.08251923]\n",
      " [0.19746391]\n",
      " [0.49584004]\n",
      " [0.70335776]\n",
      " [0.8803889 ]\n",
      " [0.962863  ]]\n",
      "step: 4400 /cost: 0.24533658 \n",
      "prediction:\n",
      " [[0.07907473]\n",
      " [0.19598006]\n",
      " [0.48555508]\n",
      " [0.70725685]\n",
      " [0.8838036 ]\n",
      " [0.96371144]]\n",
      "step: 4600 /cost: 0.23958491 \n",
      "prediction:\n",
      " [[0.07581922]\n",
      " [0.19450319]\n",
      " [0.4755741 ]\n",
      " [0.71105963]\n",
      " [0.88708544]\n",
      " [0.9645422 ]]\n",
      "step: 4800 /cost: 0.23407866 \n",
      "prediction:\n",
      " [[0.07273883]\n",
      " [0.19302918]\n",
      " [0.46589467]\n",
      " [0.71476644]\n",
      " [0.89023995]\n",
      " [0.96535605]]\n",
      "step: 5000 /cost: 0.22880423 \n",
      "prediction:\n",
      " [[0.06982143]\n",
      " [0.19155605]\n",
      " [0.45651364]\n",
      " [0.7183796 ]\n",
      " [0.8932735 ]\n",
      " [0.96615356]]\n",
      "step: 5200 /cost: 0.2237487 \n",
      "prediction:\n",
      " [[0.06705607]\n",
      " [0.19008248]\n",
      " [0.44742492]\n",
      " [0.7219009 ]\n",
      " [0.8961911 ]\n",
      " [0.9669347 ]]\n",
      "step: 5400 /cost: 0.21890013 \n",
      "prediction:\n",
      " [[0.06443299]\n",
      " [0.18860851]\n",
      " [0.43862244]\n",
      " [0.725333  ]\n",
      " [0.8989985 ]\n",
      " [0.96769965]]\n",
      "step: 5600 /cost: 0.21424706 \n",
      "prediction:\n",
      " [[0.06194317]\n",
      " [0.18713436]\n",
      " [0.43009844]\n",
      " [0.7286781 ]\n",
      " [0.9017001 ]\n",
      " [0.9684484 ]]\n",
      "step: 5800 /cost: 0.20977916 \n",
      "prediction:\n",
      " [[0.05957849]\n",
      " [0.18566056]\n",
      " [0.42184475]\n",
      " [0.7319383 ]\n",
      " [0.9043004 ]\n",
      " [0.9691806 ]]\n",
      "step: 6000 /cost: 0.20548634 \n",
      "prediction:\n",
      " [[0.05733142]\n",
      " [0.1841883 ]\n",
      " [0.41385344]\n",
      " [0.7351169 ]\n",
      " [0.9068042 ]\n",
      " [0.96989655]]\n",
      "step: 6200 /cost: 0.20135929 \n",
      "prediction:\n",
      " [[0.05519491]\n",
      " [0.1827185 ]\n",
      " [0.40611553]\n",
      " [0.7382161 ]\n",
      " [0.9092155 ]\n",
      " [0.9705959 ]]\n",
      "step: 6400 /cost: 0.19738925 \n",
      "prediction:\n",
      " [[0.05316253]\n",
      " [0.18125227]\n",
      " [0.39862257]\n",
      " [0.7412385 ]\n",
      " [0.9115385 ]\n",
      " [0.97127897]]\n",
      "step: 6600 /cost: 0.19356821 \n",
      "prediction:\n",
      " [[0.05122836]\n",
      " [0.17979111]\n",
      " [0.39136642]\n",
      " [0.74418706]\n",
      " [0.9137771 ]\n",
      " [0.9719454 ]]\n",
      "step: 6800 /cost: 0.18988825 \n",
      "prediction:\n",
      " [[0.04938659]\n",
      " [0.17833567]\n",
      " [0.38433778]\n",
      " [0.74706376]\n",
      " [0.9159348 ]\n",
      " [0.97259563]]\n",
      "step: 7000 /cost: 0.18634248 \n",
      "prediction:\n",
      " [[0.04763213]\n",
      " [0.17688745]\n",
      " [0.3775291 ]\n",
      " [0.7498715 ]\n",
      " [0.9180152 ]\n",
      " [0.9732295 ]]\n",
      "step: 7200 /cost: 0.1829238 \n",
      "prediction:\n",
      " [[0.04595995]\n",
      " [0.17544718]\n",
      " [0.37093154]\n",
      " [0.75261223]\n",
      " [0.9200216 ]\n",
      " [0.9738473 ]]\n",
      "step: 7400 /cost: 0.17962609 \n",
      "prediction:\n",
      " [[0.04436555]\n",
      " [0.17401594]\n",
      " [0.3645375 ]\n",
      " [0.7552884 ]\n",
      " [0.9219574 ]\n",
      " [0.9744493 ]]\n",
      "step: 7600 /cost: 0.17644317 \n",
      "prediction:\n",
      " [[0.04284451]\n",
      " [0.17259447]\n",
      " [0.35833904]\n",
      " [0.75790244]\n",
      " [0.9238255 ]\n",
      " [0.97503555]]\n",
      "step: 7800 /cost: 0.17336969 \n",
      "prediction:\n",
      " [[0.04139289]\n",
      " [0.17118372]\n",
      " [0.35232908]\n",
      " [0.7604563 ]\n",
      " [0.9256288 ]\n",
      " [0.9756064 ]]\n",
      "step: 8000 /cost: 0.17040022 \n",
      "prediction:\n",
      " [[0.04000687]\n",
      " [0.1697843 ]\n",
      " [0.34650016]\n",
      " [0.76295197]\n",
      " [0.92737013]\n",
      " [0.97616196]]\n",
      "step: 8200 /cost: 0.16752978 \n",
      "prediction:\n",
      " [[0.03868287]\n",
      " [0.16839683]\n",
      " [0.34084514]\n",
      " [0.76539147]\n",
      " [0.9290522 ]\n",
      " [0.97670275]]\n",
      "step: 8400 /cost: 0.16475375 \n",
      "prediction:\n",
      " [[0.03741752]\n",
      " [0.16702162]\n",
      " [0.3353571 ]\n",
      " [0.76777637]\n",
      " [0.93067724]\n",
      " [0.97722876]]\n",
      "step: 8600 /cost: 0.1620677 \n",
      "prediction:\n",
      " [[0.03620773]\n",
      " [0.16565958]\n",
      " [0.33003032]\n",
      " [0.77010924]\n",
      " [0.932248  ]\n",
      " [0.97774065]]\n",
      "step: 8800 /cost: 0.15946753 \n",
      "prediction:\n",
      " [[0.03505054]\n",
      " [0.16431096]\n",
      " [0.3248584 ]\n",
      " [0.77239144]\n",
      " [0.9337668 ]\n",
      " [0.9782386 ]]\n",
      "step: 9000 /cost: 0.15694934 \n",
      "prediction:\n",
      " [[0.03394321]\n",
      " [0.1629762 ]\n",
      " [0.3198357 ]\n",
      " [0.77462494]\n",
      " [0.9352356 ]\n",
      " [0.97872293]]\n",
      "step: 9200 /cost: 0.15450941 \n",
      "prediction:\n",
      " [[0.03288304]\n",
      " [0.16165511]\n",
      " [0.3149552 ]\n",
      " [0.7768101 ]\n",
      " [0.93665636]\n",
      " [0.97919387]]\n",
      "step: 9400 /cost: 0.15214424 \n",
      "prediction:\n",
      " [[0.03186768]\n",
      " [0.16034867]\n",
      " [0.31021318]\n",
      " [0.77895033]\n",
      " [0.93803144]\n",
      " [0.979652  ]]\n",
      "step: 9600 /cost: 0.14985059 \n",
      "prediction:\n",
      " [[0.03089478]\n",
      " [0.15905662]\n",
      " [0.3056034 ]\n",
      " [0.78104585]\n",
      " [0.9393625 ]\n",
      " [0.9800975 ]]\n",
      "step: 9800 /cost: 0.14762533 \n",
      "prediction:\n",
      " [[0.02996215]\n",
      " [0.15777929]\n",
      " [0.30112135]\n",
      " [0.78309864]\n",
      " [0.94065154]\n",
      " [0.9805306 ]]\n",
      "step: 10000 /cost: 0.14546557 \n",
      "prediction:\n",
      " [[0.02906775]\n",
      " [0.15651654]\n",
      " [0.29676172]\n",
      " [0.7851095 ]\n",
      " [0.94189996]\n",
      " [0.98095185]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print('step:',step,'/cost:',cost_val,'\\nprediction:\\n', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis: [[0.02906338]\n",
      " [0.15651031]\n",
      " [0.29674032]\n",
      " [0.78511953]\n",
      " [0.9419061 ]\n",
      " [0.98095393]] \n",
      "Correct(Y): [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "h,c,a = sess.run([hypothesis, predicted, accuracy],\n",
    "                 feed_dict={X:x_data, Y:y_data})\n",
    "print('\\nHypothesis:', h, '\\nCorrect(Y):',c,'\\nAccuracy:',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
